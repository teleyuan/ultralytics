"""
è¶…å‚æ•°è°ƒä¼˜æ¨¡å—

è¯¥æ¨¡å—æä¾›äº† Ultralytics YOLO æ¨¡å‹çš„è¶…å‚æ•°è°ƒä¼˜åŠŸèƒ½ï¼Œæ”¯æŒç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€
å›¾åƒåˆ†ç±»ã€å§¿æ€ä¼°è®¡å’Œå¤šç›®æ ‡è·Ÿè¸ªç­‰ä»»åŠ¡ã€‚

è¶…å‚æ•°è°ƒä¼˜æ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§æœç´¢æœ€ä¼˜è¶…å‚æ•°ç»„åˆçš„è¿‡ç¨‹ï¼Œä»¥è·å¾—æœ€ä½³æ¨¡å‹æ€§èƒ½ã€‚
åœ¨ YOLO ç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼Œè¶…å‚æ•°çš„å¾®å°å˜åŒ–å¯èƒ½å¯¼è‡´æ¨¡å‹ç²¾åº¦å’Œæ•ˆç‡çš„æ˜¾è‘—å·®å¼‚ã€‚

ä¸»è¦åŠŸèƒ½:
    - ä½¿ç”¨è¿›åŒ–ç®—æ³•æœç´¢æœ€ä¼˜è¶…å‚æ•°
    - æ”¯æŒæœ¬åœ° CSV å­˜å‚¨å’Œåˆ†å¸ƒå¼ MongoDB åè°ƒ
    - è‡ªåŠ¨è®°å½•å’Œå¯è§†åŒ–è°ƒä¼˜ç»“æœ
    - æ”¯æŒè‡ªå®šä¹‰æœç´¢ç©ºé—´

Examples:
    åœ¨ COCO8 æ•°æ®é›†ä¸Šè°ƒä¼˜ YOLO11nï¼Œå›¾åƒå°ºå¯¸ 640ï¼Œè®­ç»ƒ 10 è½®ï¼Œè¿›è¡Œ 300 æ¬¡è°ƒä¼˜è¿­ä»£:
    >>> from ultralytics import YOLO
    >>> model = YOLO("yolo11n.pt")
    >>> model.tune(data="coco8.yaml", epochs=10, iterations=300, optimizer="AdamW", plots=False, save=False, val=False)
"""

from __future__ import annotations  # å¯ç”¨å»¶è¿Ÿç±»å‹æ³¨è§£è¯„ä¼°

import gc  # åƒåœ¾å›æ”¶
import random  # éšæœºæ•°ç”Ÿæˆ
import shutil  # æ–‡ä»¶æ“ä½œå·¥å…·
import subprocess  # å­è¿›ç¨‹ç®¡ç†
import time  # æ—¶é—´ç›¸å…³å‡½æ•°
from datetime import datetime  # æ—¥æœŸæ—¶é—´å¤„ç†

import numpy as np  # æ•°ç»„å’Œæ•°å€¼è®¡ç®—
import torch  # PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶

# é…ç½®å’Œå·¥å…·å¯¼å…¥
from ultralytics.cfg import get_cfg, get_save_dir  # é…ç½®ç®¡ç†å’Œä¿å­˜ç›®å½•è·å–
from ultralytics.utils import DEFAULT_CFG, LOGGER, YAML, callbacks, colorstr, remove_colorstr  # å·¥å…·å‡½æ•°
from ultralytics.utils.checks import check_requirements  # ä¾èµ–æ£€æŸ¥
from ultralytics.utils.patches import torch_load  # å®‰å…¨çš„æ¨¡å‹åŠ è½½
from ultralytics.utils.plotting import plot_tune_results  # ç»“æœå¯è§†åŒ–


class Tuner:
    """ç”¨äº YOLO æ¨¡å‹è¶…å‚æ•°è°ƒä¼˜çš„ç±»ã€‚

    è¯¥ç±»é€šè¿‡æ ¹æ®æœç´¢ç©ºé—´å˜å¼‚è¶…å‚æ•°å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹æ¥è¯„ä¼°å…¶æ€§èƒ½ï¼Œåœ¨ç»™å®šçš„è¿­ä»£æ¬¡æ•°å†…è¿›åŒ–
    YOLO æ¨¡å‹çš„è¶…å‚æ•°ã€‚æ”¯æŒæœ¬åœ° CSV å­˜å‚¨å’Œåˆ†å¸ƒå¼ MongoDB Atlas åè°ƒï¼Œç”¨äºå¤šæœºè¶…å‚æ•°ä¼˜åŒ–ã€‚

    å±æ€§:
        space (dict[str, tuple]): åŒ…å«å˜å¼‚è¾¹ç•Œå’Œç¼©æ”¾å› å­çš„è¶…å‚æ•°æœç´¢ç©ºé—´ã€‚
        tune_dir (Path): ä¿å­˜è¿›åŒ–æ—¥å¿—å’Œç»“æœçš„ç›®å½•ã€‚
        tune_csv (Path): ä¿å­˜è¿›åŒ–æ—¥å¿—çš„ CSV æ–‡ä»¶è·¯å¾„ã€‚
        args (dict): è°ƒä¼˜è¿‡ç¨‹çš„é…ç½®å‚æ•°ã€‚
        callbacks (list): è°ƒä¼˜æœŸé—´æ‰§è¡Œçš„å›è°ƒå‡½æ•°ã€‚
        prefix (str): æ—¥å¿—æ¶ˆæ¯çš„å‰ç¼€å­—ç¬¦ä¸²ã€‚
        mongodb (MongoClient): ç”¨äºåˆ†å¸ƒå¼è°ƒä¼˜çš„å¯é€‰ MongoDB å®¢æˆ·ç«¯ã€‚
        collection (Collection): ç”¨äºå­˜å‚¨è°ƒä¼˜ç»“æœçš„ MongoDB é›†åˆã€‚

    æ–¹æ³•:
        _mutate: åŸºäºè¾¹ç•Œå’Œç¼©æ”¾å› å­å˜å¼‚è¶…å‚æ•°ã€‚
        __call__: åœ¨å¤šæ¬¡è¿­ä»£ä¸­æ‰§è¡Œè¶…å‚æ•°è¿›åŒ–ã€‚

    ç¤ºä¾‹:
        åœ¨ COCO8 æ•°æ®é›†ä¸Šä¸º YOLO11n è°ƒä¼˜è¶…å‚æ•°ï¼Œå›¾åƒå¤§å° 640ï¼Œè®­ç»ƒ 10 ä¸ª epochï¼Œè¿›è¡Œ 300 æ¬¡è°ƒä¼˜è¿­ä»£ã€‚
        >>> from ultralytics import YOLO
        >>> model = YOLO("yolo11n.pt")
        >>> model.tune(
        >>>     data="coco8.yaml",
        >>>     epochs=10,
        >>>     iterations=300,
        >>>     plots=False,
        >>>     save=False,
        >>>     val=False
        >>> )

        ä½¿ç”¨åˆ†å¸ƒå¼ MongoDB Atlas åè°ƒåœ¨å¤šå°æœºå™¨ä¸Šè¿›è¡Œè°ƒä¼˜:
        >>> model.tune(
        >>>     data="coco8.yaml",
        >>>     epochs=10,
        >>>     iterations=300,
        >>>     mongodb_uri="mongodb+srv://user:pass@cluster.mongodb.net/",
        >>>     mongodb_db="ultralytics",
        >>>     mongodb_collection="tune_results"
        >>> )

        ä½¿ç”¨è‡ªå®šä¹‰æœç´¢ç©ºé—´è¿›è¡Œè°ƒä¼˜:
        >>> model.tune(space={"lr0": (1e-5, 1e-1), "momentum": (0.6, 0.98)})
    """

    def __init__(self, args=DEFAULT_CFG, _callbacks: list | None = None):
        """åˆå§‹åŒ–è¶…å‚æ•°è°ƒä¼˜å™¨

        Args:
            args (dict): è¶…å‚æ•°è¿›åŒ–çš„é…ç½®å­—å…¸
            _callbacks (list | None, optional): è°ƒä¼˜è¿‡ç¨‹ä¸­æ‰§è¡Œçš„å›è°ƒå‡½æ•°åˆ—è¡¨
        """
        # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´ï¼Œæ ¼å¼ä¸º key: (æœ€å°å€¼, æœ€å¤§å€¼, å¢ç›Šç³»æ•°(å¯é€‰))
        self.space = args.pop("space", None) or {
            # 'optimizer': tune.choice(['SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp']),
            "lr0": (1e-5, 1e-1),  # åˆå§‹å­¦ä¹ ç‡ (SGD=1E-2, Adam=1E-3)
            "lrf": (0.0001, 0.1),  # OneCycleLR æœ€ç»ˆå­¦ä¹ ç‡ (lr0 * lrf)
            "momentum": (0.7, 0.98, 0.3),  # SGD åŠ¨é‡/Adam beta1 å‚æ•°
            "weight_decay": (0.0, 0.001),  # ä¼˜åŒ–å™¨æƒé‡è¡°å‡ç³»æ•°
            "warmup_epochs": (0.0, 5.0),  # é¢„çƒ­è½®æ•°ï¼ˆå¯ä»¥æ˜¯å°æ•°ï¼‰
            "warmup_momentum": (0.0, 0.95),  # é¢„çƒ­åˆå§‹åŠ¨é‡
            "box": (1.0, 20.0),  # è¾¹ç•Œæ¡†æŸå¤±å¢ç›Š
            "cls": (0.1, 4.0),  # åˆ†ç±»æŸå¤±å¢ç›Šï¼ˆéšåƒç´ ç¼©æ”¾ï¼‰
            "dfl": (0.4, 6.0),  # DFLï¼ˆDistribution Focal Lossï¼‰æŸå¤±å¢ç›Š
            "hsv_h": (0.0, 0.1),  # HSV-è‰²è°ƒå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "hsv_s": (0.0, 0.9),  # HSV-é¥±å’Œåº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "hsv_v": (0.0, 0.9),  # HSV-æ˜åº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "degrees": (0.0, 45.0),  # å›¾åƒæ—‹è½¬è§’åº¦ (+/- deg)
            "translate": (0.0, 0.9),  # å›¾åƒå¹³ç§»æ¯”ä¾‹ (+/- fraction)
            "scale": (0.0, 0.95),  # å›¾åƒç¼©æ”¾æ¯”ä¾‹ (+/- gain)
            "shear": (0.0, 10.0),  # å›¾åƒå‰ªåˆ‡è§’åº¦ (+/- deg)
            "perspective": (0.0, 0.001),  # å›¾åƒé€è§†å˜æ¢ (+/- fraction)ï¼ŒèŒƒå›´ 0-0.001
            "flipud": (0.0, 1.0),  # å›¾åƒä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
            "fliplr": (0.0, 1.0),  # å›¾åƒå·¦å³ç¿»è½¬æ¦‚ç‡
            "bgr": (0.0, 1.0),  # å›¾åƒé€šé“ BGR è½¬æ¢æ¦‚ç‡
            "mosaic": (0.0, 1.0),  # é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡
            "mixup": (0.0, 1.0),  # MixUp å¢å¼ºæ¦‚ç‡
            "cutmix": (0.0, 1.0),  # CutMix å¢å¼ºæ¦‚ç‡
            "copy_paste": (0.0, 1.0),  # åˆ†å‰²ä»»åŠ¡çš„å¤åˆ¶ç²˜è´´å¢å¼ºæ¦‚ç‡
            "close_mosaic": (0.0, 10.0),  # å…³é—­é©¬èµ›å…‹å¢å¼ºçš„è½®æ•°
        }
        # ä»é…ç½®ä¸­æå– MongoDB ç›¸å…³å‚æ•°
        mongodb_uri = args.pop("mongodb_uri", None)
        mongodb_db = args.pop("mongodb_db", "ultralytics")
        mongodb_collection = args.pop("mongodb_collection", "tuner_results")

        # è·å–å¹¶è®¾ç½®é…ç½®
        self.args = get_cfg(overrides=args)
        self.args.exist_ok = self.args.resume  # æ¢å¤è®­ç»ƒæ—¶å…è®¸ä½¿ç”¨ç›¸åŒçš„ tune_dir
        self.tune_dir = get_save_dir(self.args, name=self.args.name or "tune")  # è·å–è°ƒä¼˜ç»“æœä¿å­˜ç›®å½•
        self.args.name, self.args.exist_ok, self.args.resume = (None, False, False)  # é‡ç½®å‚æ•°ä»¥å…å½±å“è®­ç»ƒ
        self.tune_csv = self.tune_dir / "tune_results.csv"  # CSV ç»“æœæ–‡ä»¶è·¯å¾„
        self.callbacks = _callbacks or callbacks.get_default_callbacks()  # è®¾ç½®å›è°ƒå‡½æ•°
        self.prefix = colorstr("Tuner: ")  # æ—¥å¿—å‰ç¼€ï¼ˆå¸¦é¢œè‰²ï¼‰
        callbacks.add_integration_callbacks(self)  # æ·»åŠ é›†æˆå›è°ƒ

        # MongoDB Atlas æ”¯æŒï¼ˆå¯é€‰ï¼Œç”¨äºåˆ†å¸ƒå¼è°ƒä¼˜ï¼‰
        self.mongodb = None
        if mongodb_uri:
            self._init_mongodb(mongodb_uri, mongodb_db, mongodb_collection)

        LOGGER.info(
            f"{self.prefix}Initialized Tuner instance with 'tune_dir={self.tune_dir}'\n"
            f"{self.prefix}ğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning"
        )

    def _connect(self, uri: str = "mongodb+srv://username:password@cluster.mongodb.net/", max_retries: int = 3):
        """åœ¨è¿æ¥å¤±è´¥æ—¶ä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•åˆ›å»º MongoDB å®¢æˆ·ç«¯ã€‚

        å‚æ•°:
            uri (str): åŒ…å«å‡­æ®å’Œé›†ç¾¤ä¿¡æ¯çš„ MongoDB è¿æ¥å­—ç¬¦ä¸²ã€‚
            max_retries (int): æ”¾å¼ƒå‰çš„æœ€å¤§è¿æ¥å°è¯•æ¬¡æ•°ã€‚

        è¿”å›:
            (MongoClient): å·²è¿æ¥çš„ MongoDB å®¢æˆ·ç«¯å®ä¾‹ã€‚
        """
        check_requirements("pymongo")

        from pymongo import MongoClient
        from pymongo.errors import ConnectionFailure, ServerSelectionTimeoutError

        for attempt in range(max_retries):
            try:
                client = MongoClient(
                    uri,
                    serverSelectionTimeoutMS=30000,
                    connectTimeoutMS=20000,
                    socketTimeoutMS=40000,
                    retryWrites=True,
                    retryReads=True,
                    maxPoolSize=30,
                    minPoolSize=3,
                    maxIdleTimeMS=60000,
                )
                client.admin.command("ping")  # Test connection
                LOGGER.info(f"{self.prefix}Connected to MongoDB Atlas (attempt {attempt + 1})")
                return client
            except (ConnectionFailure, ServerSelectionTimeoutError):
                if attempt == max_retries - 1:
                    raise
                wait_time = 2**attempt
                LOGGER.warning(
                    f"{self.prefix}MongoDB connection failed (attempt {attempt + 1}), retrying in {wait_time}s..."
                )
                time.sleep(wait_time)

    def _init_mongodb(self, mongodb_uri="", mongodb_db="", mongodb_collection=""):
        """åˆå§‹åŒ–ç”¨äºåˆ†å¸ƒå¼è°ƒä¼˜çš„ MongoDB è¿æ¥ã€‚

        è¿æ¥åˆ° MongoDB Atlas ä»¥åœ¨å¤šå°æœºå™¨ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è¶…å‚æ•°ä¼˜åŒ–ã€‚æ¯ä¸ªå·¥ä½œè¿›ç¨‹
        å°†ç»“æœä¿å­˜åˆ°å…±äº«é›†åˆï¼Œå¹¶ä»æ‰€æœ‰å·¥ä½œè¿›ç¨‹è¯»å–æœ€æ–°çš„æœ€ä½³è¶…å‚æ•°ç”¨äºè¿›åŒ–ã€‚

        å‚æ•°:
            mongodb_uri (str): MongoDB è¿æ¥å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ 'mongodb+srv://username:password@cluster.mongodb.net/'ã€‚
            mongodb_db (str, optional): æ•°æ®åº“åç§°ã€‚
            mongodb_collection (str, optional): é›†åˆåç§°ã€‚

        æ³¨æ„:
            - åˆ›å»ºé€‚åº”åº¦ç´¢å¼•ä»¥å¿«é€ŸæŸ¥è¯¢æœ€ä½³ç»“æœ
            - å¦‚æœè¿æ¥å¤±è´¥åˆ™å›é€€åˆ°ä»… CSV æ¨¡å¼
            - ä½¿ç”¨è¿æ¥æ± å’Œé‡è¯•é€»è¾‘ä»¥ç¡®ä¿ç”Ÿäº§ç¯å¢ƒå¯é æ€§
        """
        self.mongodb = self._connect(mongodb_uri)
        self.collection = self.mongodb[mongodb_db][mongodb_collection]
        self.collection.create_index([("fitness", -1)], background=True)
        LOGGER.info(f"{self.prefix}Using MongoDB Atlas for distributed tuning")

    def _get_mongodb_results(self, n: int = 5) -> list:
        """ä» MongoDB è·å–æŒ‰é€‚åº”åº¦æ’åºçš„å‰ N ä¸ªç»“æœã€‚

        å‚æ•°:
            n (int): è¦æ£€ç´¢çš„æœ€ä½³ç»“æœæ•°é‡ã€‚

        è¿”å›:
            (list[dict]): åŒ…å«é€‚åº”åº¦åˆ†æ•°å’Œè¶…å‚æ•°çš„ç»“æœæ–‡æ¡£åˆ—è¡¨ã€‚
        """
        try:
            return list(self.collection.find().sort("fitness", -1).limit(n))
        except Exception:
            return []

    def _save_to_mongodb(self, fitness: float, hyperparameters: dict[str, float], metrics: dict, iteration: int):
        """å°†ç»“æœä»¥æ­£ç¡®çš„ç±»å‹è½¬æ¢ä¿å­˜åˆ° MongoDBã€‚

        å‚æ•°:
            fitness (float): ä½¿ç”¨è¿™äº›è¶…å‚æ•°è·å¾—çš„é€‚åº”åº¦åˆ†æ•°ã€‚
            hyperparameters (dict[str, float]): è¶…å‚æ•°å€¼å­—å…¸ã€‚
            metrics (dict): å®Œæ•´çš„è®­ç»ƒæŒ‡æ ‡å­—å…¸(mAPã€ç²¾ç¡®åº¦ã€å¬å›ç‡ã€æŸå¤±ç­‰)ã€‚
            iteration (int): å½“å‰è¿­ä»£ç¼–å·ã€‚
        """
        try:
            self.collection.insert_one(
                {
                    "fitness": fitness,
                    "hyperparameters": {k: (v.item() if hasattr(v, "item") else v) for k, v in hyperparameters.items()},
                    "metrics": metrics,
                    "timestamp": datetime.now(),
                    "iteration": iteration,
                }
            )
        except Exception as e:
            LOGGER.warning(f"{self.prefix}MongoDB save failed: {e}")

    def _sync_mongodb_to_csv(self):
        """å°† MongoDB ç»“æœåŒæ­¥åˆ° CSV ä»¥å®ç°ç»˜å›¾å…¼å®¹æ€§ã€‚

        ä» MongoDB ä¸‹è½½æ‰€æœ‰ç»“æœå¹¶æŒ‰æ—¶é—´é¡ºåºå°†å®ƒä»¬å†™å…¥æœ¬åœ° CSV æ–‡ä»¶ã€‚è¿™ä½¿å¾—
        ç°æœ‰çš„ç»˜å›¾å‡½æ•°èƒ½å¤Ÿæ— ç¼å¤„ç†åˆ†å¸ƒå¼ MongoDB æ•°æ®ã€‚
        """
        try:
            # Get all results from MongoDB
            all_results = list(self.collection.find().sort("iteration", 1))
            if not all_results:
                return

            # Write to CSV
            headers = ",".join(["fitness", *list(self.space.keys())]) + "\n"
            with open(self.tune_csv, "w", encoding="utf-8") as f:
                f.write(headers)
                for result in all_results:
                    fitness = result["fitness"]
                    hyp_values = [result["hyperparameters"][k] for k in self.space.keys()]
                    log_row = [round(fitness, 5), *hyp_values]
                    f.write(",".join(map(str, log_row)) + "\n")

        except Exception as e:
            LOGGER.warning(f"{self.prefix}MongoDB to CSV sync failed: {e}")

    @staticmethod
    def _crossover(x: np.ndarray, alpha: float = 0.2, k: int = 9) -> np.ndarray:
        """BLX-Î± äº¤å‰æ“ä½œï¼Œä»å‰ k ä¸ªçˆ¶ä»£ä¸­è¿›è¡Œæ··åˆ (x[:,0]=é€‚åº”åº¦, å…¶ä½™=åŸºå› )

        ä½¿ç”¨ BLX-Î±ï¼ˆBlend Crossover Alphaï¼‰ç®—æ³•ä»å¤šä¸ªä¼˜ç§€çˆ¶ä»£ä¸­ç”Ÿæˆæ–°çš„è¶…å‚æ•°ç»„åˆã€‚

        Args:
            x: çˆ¶ä»£çŸ©é˜µï¼Œç¬¬ä¸€åˆ—æ˜¯é€‚åº”åº¦ï¼Œå…¶ä½™åˆ—æ˜¯è¶…å‚æ•°å€¼
            alpha: äº¤å‰æ··åˆç³»æ•°ï¼Œæ§åˆ¶æœç´¢èŒƒå›´çš„æ‰©å±•
            k: å‚ä¸äº¤å‰çš„çˆ¶ä»£æ•°é‡

        Returns:
            æ–°ç”Ÿæˆçš„è¶…å‚æ•°å‘é‡
        """
        k = min(k, len(x))  # ç¡®ä¿ k ä¸è¶…è¿‡å¯ç”¨çš„çˆ¶ä»£æ•°é‡
        # è®¡ç®—é€‚åº”åº¦æƒé‡ï¼ˆåç§»åˆ° >0ï¼‰ï¼›å¦‚æœé€€åŒ–åˆ™å›é€€åˆ°å‡åŒ€åˆ†å¸ƒ
        weights = x[:, 0] - x[:, 0].min() + 1e-6
        if not np.isfinite(weights).all() or weights.sum() == 0:
            weights = np.ones_like(weights)
        # æ ¹æ®é€‚åº”åº¦æƒé‡éšæœºé€‰æ‹© k ä¸ªçˆ¶ä»£
        idxs = random.choices(range(len(x)), weights=weights, k=k)
        parents_mat = np.stack([x[i][1:] for i in idxs], 0)  # (k, ng) å»é™¤é€‚åº”åº¦åˆ—
        # è®¡ç®—æ‰€æœ‰çˆ¶ä»£åŸºå› çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
        lo, hi = parents_mat.min(0), parents_mat.max(0)
        span = hi - lo
        # åœ¨æ‰©å±•çš„èŒƒå›´å†…å‡åŒ€é‡‡æ ·ç”Ÿæˆæ–°åŸºå› 
        return np.random.uniform(lo - alpha * span, hi + alpha * span)

    def _mutate(
        self,
        n: int = 9,
        mutation: float = 0.5,
        sigma: float = 0.2,
    ) -> dict[str, float]:
        """åŸºäº self.space ä¸­æŒ‡å®šçš„è¾¹ç•Œå’Œç¼©æ”¾å› å­å˜å¼‚è¶…å‚æ•°

        ä½¿ç”¨è¿›åŒ–ç®—æ³•ä¸­çš„äº¤å‰å’Œå˜å¼‚æ“ä½œç”Ÿæˆæ–°çš„è¶…å‚æ•°ç»„åˆã€‚
        ä¼˜å…ˆä» MongoDB è¯»å–å†å²æœ€ä¼˜ç»“æœï¼Œå¦åˆ™ä» CSV æ–‡ä»¶è¯»å–ã€‚

        Args:
            n (int): è€ƒè™‘çš„æœ€ä¼˜çˆ¶ä»£æ•°é‡
            mutation (float): æ¯æ¬¡è¿­ä»£ä¸­å‚æ•°å‘ç”Ÿå˜å¼‚çš„æ¦‚ç‡
            sigma (float): é«˜æ–¯éšæœºæ•°ç”Ÿæˆå™¨çš„æ ‡å‡†å·®

        Returns:
            (dict[str, float]): åŒ…å«å˜å¼‚åè¶…å‚æ•°çš„å­—å…¸
        """
        x = None

        # å¦‚æœå¯ç”¨ï¼Œä¼˜å…ˆå°è¯•ä» MongoDB è·å–å†å²ç»“æœ
        if self.mongodb:
            if results := self._get_mongodb_results(n):
                # MongoDB å·²æŒ‰é€‚åº”åº¦é™åºæ’åºï¼Œresults[0] æ˜¯æœ€ä½³ç»“æœ
                x = np.array([[r["fitness"]] + [r["hyperparameters"][k] for k in self.space.keys()] for r in results])
            elif self.collection.name in self.collection.database.list_collection_names():  # è°ƒä¼˜å™¨åœ¨å…¶ä»–åœ°æ–¹å¯åŠ¨
                x = np.array([[0.0] + [getattr(self.args, k) for k in self.space.keys()]])

        # å¦‚æœ MongoDB ä¸å¯ç”¨æˆ–ä¸ºç©ºï¼Œå›é€€åˆ° CSV æ–‡ä»¶
        if x is None and self.tune_csv.exists():
            csv_data = np.loadtxt(self.tune_csv, ndmin=2, delimiter=",", skiprows=1)
            if len(csv_data) > 0:
                fitness = csv_data[:, 0]  # ç¬¬ä¸€åˆ—æ˜¯é€‚åº”åº¦
                order = np.argsort(-fitness)  # æŒ‰é€‚åº”åº¦é™åºæ’åº
                x = csv_data[order][:n]  # å–å‰ n ä¸ªæœ€ä¼˜ç»“æœ

        # å¦‚æœæœ‰å†å²æ•°æ®åˆ™è¿›è¡Œå˜å¼‚ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if x is not None:
            np.random.seed(int(time.time()))  # è®¾ç½®éšæœºç§å­
            ng = len(self.space)  # è¶…å‚æ•°æ•°é‡

            # æ­¥éª¤ 1: äº¤å‰æ“ä½œ - ä»å¤šä¸ªçˆ¶ä»£ä¸­æ··åˆç”Ÿæˆæ–°åŸºå› 
            genes = self._crossover(x)

            # æ­¥éª¤ 2: å˜å¼‚æ“ä½œ - æ·»åŠ éšæœºæ‰°åŠ¨
            gains = np.array([v[2] if len(v) == 3 else 1.0 for v in self.space.values()])  # å¢ç›Šç³»æ•° 0-1
            factors = np.ones(ng)  # å˜å¼‚å› å­åˆå§‹åŒ–ä¸º 1
            while np.all(factors == 1):  # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå‚æ•°å‘ç”Ÿå˜åŒ–ï¼ˆé˜²æ­¢é‡å¤ï¼‰
                mask = np.random.random(ng) < mutation  # éšæœºé€‰æ‹©è¦å˜å¼‚çš„å‚æ•°
                step = np.random.randn(ng) * (sigma * gains)  # é«˜æ–¯æ‰°åŠ¨æ­¥é•¿
                factors = np.where(mask, np.exp(step), 1.0).clip(0.25, 4.0)  # è®¡ç®—å˜å¼‚å› å­å¹¶é™åˆ¶èŒƒå›´
            hyp = {k: float(genes[i] * factors[i]) for i, k in enumerate(self.space.keys())}
        else:
            # æ²¡æœ‰å†å²æ•°æ®æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
            hyp = {k: getattr(self.args, k) for k in self.space.keys()}

        # å°†è¶…å‚æ•°é™åˆ¶åœ¨æŒ‡å®šçš„è¾¹ç•ŒèŒƒå›´å†…
        for k, bounds in self.space.items():
            hyp[k] = round(min(max(hyp[k], bounds[0]), bounds[1]), 5)

        # æ›´æ–°ç‰¹å®šå‚æ•°çš„ç±»å‹ï¼ˆä¾‹å¦‚å°† close_mosaic è½¬ä¸ºæ•´æ•°ï¼‰
        if "close_mosaic" in hyp:
            hyp["close_mosaic"] = round(hyp["close_mosaic"])

        return hyp

    def __call__(self, model=None, iterations: int = 10, cleanup: bool = True):
        """æ‰§è¡Œè¶…å‚æ•°è¿›åŒ–è¿‡ç¨‹ï¼ˆå½“ Tuner å®ä¾‹è¢«è°ƒç”¨æ—¶ï¼‰

        è¯¥æ–¹æ³•é€šè¿‡æŒ‡å®šæ•°é‡çš„è¿­ä»£æ‰§è¡Œè¶…å‚æ•°è°ƒä¼˜ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤:
        1. åŒæ­¥ MongoDB ç»“æœåˆ° CSVï¼ˆå¦‚æœä½¿ç”¨åˆ†å¸ƒå¼æ¨¡å¼ï¼‰
        2. ä½¿ç”¨æœ€ä½³å†å²ç»“æœæˆ–é»˜è®¤å€¼å˜å¼‚è¶…å‚æ•°
        3. ä½¿ç”¨å˜å¼‚åçš„è¶…å‚æ•°è®­ç»ƒ YOLO æ¨¡å‹
        4. å°†é€‚åº”åº¦åˆ†æ•°å’Œè¶…å‚æ•°è®°å½•åˆ° MongoDB å’Œ/æˆ– CSV
        5. è·Ÿè¸ªæ‰€æœ‰è¿­ä»£ä¸­æ€§èƒ½æœ€ä½³çš„é…ç½®

        Args:
            model (Model | None, optional): é¢„åˆå§‹åŒ–çš„ YOLO æ¨¡å‹ç”¨äºè®­ç»ƒ
            iterations (int): è¿›åŒ–è¿è¡Œçš„ä»£æ•°
            cleanup (bool): æ˜¯å¦åˆ é™¤è¿­ä»£æƒé‡ä»¥å‡å°‘è°ƒä¼˜æœŸé—´çš„å­˜å‚¨ç©ºé—´
        """
        t0 = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        best_save_dir, best_metrics = None, None  # æœ€ä½³æ¨¡å‹çš„ä¿å­˜ç›®å½•å’ŒæŒ‡æ ‡
        (self.tune_dir / "weights").mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæƒé‡ä¿å­˜ç›®å½•

        # å¯åŠ¨æ—¶åŒæ­¥ MongoDB åˆ° CSV ä»¥æ”¯æŒæ¢å¤é€»è¾‘
        if self.mongodb:
            self._sync_mongodb_to_csv()

        # æ£€æŸ¥æ˜¯å¦æœ‰å†å²è®°å½•ä»¥æ”¯æŒæ¢å¤è®­ç»ƒ
        start = 0
        if self.tune_csv.exists():
            x = np.loadtxt(self.tune_csv, ndmin=2, delimiter=",", skiprows=1)
            start = x.shape[0]  # å·²å®Œæˆçš„è¿­ä»£æ¬¡æ•°
            LOGGER.info(f"{self.prefix}Resuming tuning run {self.tune_dir} from iteration {start + 1}...")

        # ä¸»è°ƒä¼˜å¾ªç¯
        for i in range(start, iterations):
            # åœ¨å‰ 300 æ¬¡è¿­ä»£ä¸­çº¿æ€§è¡°å‡ sigma ä» 0.2 â†’ 0.1
            frac = min(i / 300.0, 1.0)
            sigma_i = 0.2 - 0.1 * frac

            # å˜å¼‚è¶…å‚æ•°ç”Ÿæˆæ–°çš„å€™é€‰é…ç½®
            mutated_hyp = self._mutate(sigma=sigma_i)
            LOGGER.info(f"{self.prefix}Starting iteration {i + 1}/{iterations} with hyperparameters: {mutated_hyp}")

            # å‡†å¤‡è®­ç»ƒå‚æ•°
            metrics = {}
            train_args = {**vars(self.args), **mutated_hyp}  # åˆå¹¶åŸºç¡€é…ç½®å’Œå˜å¼‚è¶…å‚æ•°
            save_dir = get_save_dir(get_cfg(train_args))
            weights_dir = save_dir / "weights"

            try:
                # åœ¨å­è¿›ç¨‹ä¸­è®­ç»ƒ YOLO æ¨¡å‹ï¼ˆé¿å…æ•°æ®åŠ è½½å™¨æŒ‚èµ·é—®é¢˜ï¼‰
                launch = [__import__("sys").executable, "-m", "ultralytics.cfg.__init__"]  # è§£å†³ yolo æœªæ‰¾åˆ°çš„é—®é¢˜
                cmd = [*launch, "train", *(f"{k}={v}" for k, v in train_args.items())]
                return_code = subprocess.run(cmd, check=True).returncode

                # åŠ è½½è®­ç»ƒæŒ‡æ ‡
                ckpt_file = weights_dir / ("best.pt" if (weights_dir / "best.pt").exists() else "last.pt")
                metrics = torch_load(ckpt_file)["train_metrics"]
                assert return_code == 0, "training failed"

                # æ¸…ç†å†…å­˜
                time.sleep(1)
                gc.collect()  # åƒåœ¾å›æ”¶
                torch.cuda.empty_cache()  # æ¸…ç©º CUDA ç¼“å­˜

            except Exception as e:
                LOGGER.error(f"training failure for hyperparameter tuning iteration {i + 1}\n{e}")

            # ä¿å­˜ç»“æœ - MongoDB ä¼˜å…ˆ
            fitness = metrics.get("fitness", 0.0)  # è·å–é€‚åº”åº¦åˆ†æ•°
            if self.mongodb:
                # ä½¿ç”¨ MongoDB åˆ†å¸ƒå¼å­˜å‚¨
                self._save_to_mongodb(fitness, mutated_hyp, metrics, i + 1)
                self._sync_mongodb_to_csv()
                total_mongo_iterations = self.collection.count_documents({})
                if total_mongo_iterations >= iterations:
                    LOGGER.info(
                        f"{self.prefix}Target iterations ({iterations}) reached in MongoDB ({total_mongo_iterations}). Stopping."
                    )
                    break
            else:
                # ä»…ä½¿ç”¨ CSV å­˜å‚¨ï¼ˆæ—  MongoDBï¼‰
                log_row = [round(fitness, 5)] + [mutated_hyp[k] for k in self.space.keys()]
                headers = "" if self.tune_csv.exists() else (",".join(["fitness", *list(self.space.keys())]) + "\n")
                with open(self.tune_csv, "a", encoding="utf-8") as f:
                    f.write(headers + ",".join(map(str, log_row)) + "\n")

            # è·å–å¹¶æ›´æ–°æœ€ä½³ç»“æœ
            x = np.loadtxt(self.tune_csv, ndmin=2, delimiter=",", skiprows=1)
            fitness = x[:, 0]  # ç¬¬ä¸€åˆ—æ˜¯é€‚åº”åº¦
            best_idx = fitness.argmax()  # æœ€ä½³é€‚åº”åº¦çš„ç´¢å¼•
            best_is_current = best_idx == i  # å½“å‰è¿­ä»£æ˜¯å¦æ˜¯æœ€ä½³

            if best_is_current:
                # å½“å‰è¿­ä»£æ˜¯æœ€ä½³ç»“æœï¼Œä¿å­˜æƒé‡
                best_save_dir = str(save_dir)
                best_metrics = {k: round(v, 5) for k, v in metrics.items()}
                for ckpt in weights_dir.glob("*.pt"):
                    shutil.copy2(ckpt, self.tune_dir / "weights")
            elif cleanup and best_save_dir:
                # åˆ é™¤éæœ€ä½³è¿­ä»£çš„ç›®å½•ä»¥å‡å°‘å­˜å‚¨ç©ºé—´
                shutil.rmtree(best_save_dir, ignore_errors=True)

            # ç»˜åˆ¶è°ƒä¼˜ç»“æœå›¾è¡¨
            plot_tune_results(str(self.tune_csv))

            # ä¿å­˜å¹¶æ‰“å°è°ƒä¼˜ç»“æœ
            header = (
                f"{self.prefix}{i + 1}/{iterations} iterations complete âœ… ({time.time() - t0:.2f}s)\n"
                f"{self.prefix}Results saved to {colorstr('bold', self.tune_dir)}\n"
                f"{self.prefix}Best fitness={fitness[best_idx]} observed at iteration {best_idx + 1}\n"
                f"{self.prefix}Best fitness metrics are {best_metrics}\n"
                f"{self.prefix}Best fitness model is {best_save_dir}"
            )
            LOGGER.info("\n" + header)

            # ä¿å­˜æœ€ä½³è¶…å‚æ•°åˆ° YAML æ–‡ä»¶
            data = {k: float(x[best_idx, i + 1]) for i, k in enumerate(self.space.keys())}
            YAML.save(
                self.tune_dir / "best_hyperparameters.yaml",
                data=data,
                header=remove_colorstr(header.replace(self.prefix, "# ")) + "\n",
            )
            YAML.print(self.tune_dir / "best_hyperparameters.yaml")
