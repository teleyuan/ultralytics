# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
æŽ¨ç†ç»“æžœå¤„ç†æ¨¡å—

è¯¥æ¨¡å—æä¾›äº† Ultralytics YOLO æ¨¡åž‹æŽ¨ç†ç»“æžœçš„å°è£…å’Œå¤„ç†ç±»ï¼ŒåŒ…æ‹¬è¾¹ç•Œæ¡†ã€æŽ©ç ã€å…³é”®ç‚¹ç­‰ã€‚
ä¸»è¦ç”¨äºŽç»Ÿä¸€å¤„ç†å„ç§æ£€æµ‹ä»»åŠ¡çš„è¾“å‡ºç»“æžœï¼Œæä¾›ä¾¿æ·çš„ç»“æžœè®¿é—®å’Œå¯è§†åŒ–æ–¹æ³•ã€‚

ä¸»è¦ç±»:
    - BaseTensor: å¼ é‡åŸºç±»ï¼Œæä¾›è®¾å¤‡ç®¡ç†å’Œç±»åž‹è½¬æ¢
    - Results: æŽ¨ç†ç»“æžœä¸»ç±»ï¼Œå°è£…å›¾åƒã€é¢„æµ‹å’Œå…ƒæ•°æ®
    - Boxes: è¾¹ç•Œæ¡†ç±»ï¼Œå¤„ç†æ£€æµ‹æ¡†æ•°æ®
    - Masks: æŽ©ç ç±»ï¼Œå¤„ç†åˆ†å‰²æŽ©ç 
    - Keypoints: å…³é”®ç‚¹ç±»ï¼Œå¤„ç†å§¿æ€ä¼°è®¡å…³é”®ç‚¹
    - Probs: æ¦‚çŽ‡ç±»ï¼Œå¤„ç†åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ¦‚çŽ‡
    - OBB: æœ‰å‘è¾¹ç•Œæ¡†ç±»ï¼Œå¤„ç†æ—‹è½¬ç›®æ ‡æ£€æµ‹

ä½¿ç”¨æ–¹æ³•: å‚è§ https://docs.ultralytics.com/modes/predict/
"""

from __future__ import annotations  # å¯ç”¨å»¶è¿Ÿç±»åž‹æ³¨è§£è¯„ä¼°

from copy import deepcopy  # æ·±æ‹·è´å¯¹è±¡
from functools import lru_cache  # LRU ç¼“å­˜è£…é¥°å™¨
from pathlib import Path  # è·¨å¹³å°è·¯å¾„æ“ä½œ
from typing import Any  # ç±»åž‹æç¤º

import numpy as np  # æ•°ç»„å’Œæ•°å€¼è®¡ç®—
import torch  # PyTorch æ·±åº¦å­¦ä¹ æ¡†æž¶

# æ•°æ®å¢žå¼ºå’Œå·¥å…·å¯¼å…¥
from ultralytics.data.augment import LetterBox  # å›¾åƒå¡«å……å˜æ¢
from ultralytics.utils import LOGGER, DataExportMixin, SimpleClass, ops  # å·¥å…·ç±»å’Œæ“ä½œ
from ultralytics.utils.plotting import Annotator, colors, save_one_box  # å¯è§†åŒ–å·¥å…·


class BaseTensor(SimpleClass):
    """åŸºç¡€å¼ é‡ç±»,æä¾›é¢å¤–çš„æ–¹æ³•ç”¨äºŽç®€ä¾¿æ“ä½œå’Œè®¾å¤‡å¤„ç†ã€‚

    è¯¥ç±»ä¸ºç±»å¼ é‡å¯¹è±¡æä¾›åŸºç¡€,å…·å¤‡è®¾å¤‡ç®¡ç†èƒ½åŠ›,æ”¯æŒ PyTorch å¼ é‡å’Œ NumPy æ•°ç»„ã€‚
    åŒ…å«åœ¨è®¾å¤‡é—´ç§»åŠ¨æ•°æ®å’Œåœ¨å¼ é‡ç±»åž‹é—´è½¬æ¢çš„æ–¹æ³•ã€‚

    Attributes:
        data (torch.Tensor | np.ndarray): é¢„æµ‹æ•°æ®,å¦‚è¾¹ç•Œæ¡†ã€æŽ©ç æˆ–å…³é”®ç‚¹ã€‚
        orig_shape (tuple[int, int]): å›¾åƒçš„åŽŸå§‹å½¢çŠ¶,é€šå¸¸ä¸º (é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    Methods:
        cpu: è¿”å›žå­˜å‚¨åœ¨ CPU å†…å­˜ä¸­çš„å¼ é‡å‰¯æœ¬ã€‚
        numpy: è¿”å›žå¼ é‡çš„ numpy æ•°ç»„å‰¯æœ¬ã€‚
        cuda: å°†å¼ é‡ç§»è‡³ GPU å†…å­˜,å¿…è¦æ—¶è¿”å›žæ–°å®žä¾‹ã€‚
        to: è¿”å›žå…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹çš„å¼ é‡å‰¯æœ¬ã€‚

    Examples:
        >>> import torch
        >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
        >>> orig_shape = (720, 1280)
        >>> base_tensor = BaseTensor(data, orig_shape)
        >>> cpu_tensor = base_tensor.cpu()
        >>> numpy_array = base_tensor.numpy()
        >>> gpu_tensor = base_tensor.cuda()
    """

    def __init__(self, data: torch.Tensor | np.ndarray, orig_shape: tuple[int, int]) -> None:
        """åˆå§‹åŒ– BaseTensorï¼ŒåŒ…å«é¢„æµ‹æ•°æ®å’ŒåŽŸå§‹å›¾åƒå½¢çŠ¶

        Args:
            data (torch.Tensor | np.ndarray): é¢„æµ‹æ•°æ®ï¼Œå¦‚è¾¹ç•Œæ¡†ã€æŽ©ç æˆ–å…³é”®ç‚¹
            orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)
        """
        assert isinstance(data, (torch.Tensor, np.ndarray)), "data must be torch.Tensor or np.ndarray"
        self.data = data  # å­˜å‚¨é¢„æµ‹æ•°æ®ï¼ˆå¼ é‡æˆ–æ•°ç»„ï¼‰
        self.orig_shape = orig_shape  # å­˜å‚¨åŽŸå§‹å›¾åƒå°ºå¯¸

    @property
    def shape(self) -> tuple[int, ...]:
        """è¿”å›žåº•å±‚æ•°æ®å¼ é‡çš„å½¢çŠ¶ã€‚

        Returns:
            (tuple[int, ...]): æ•°æ®å¼ é‡çš„å½¢çŠ¶ã€‚

        Examples:
            >>> data = torch.rand(100, 4)
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> print(base_tensor.shape)
            (100, 4)
        """
        return self.data.shape

    def cpu(self):
        """è¿”å›žå­˜å‚¨åœ¨ CPU å†…å­˜ä¸­çš„å¼ é‡å‰¯æœ¬ã€‚

        Returns:
            (BaseTensor): æ•°æ®å¼ é‡å·²ç§»è‡³ CPU å†…å­˜çš„æ–° BaseTensor å¯¹è±¡ã€‚

        Examples:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]]).cuda()
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> cpu_tensor = base_tensor.cpu()
            >>> isinstance(cpu_tensor, BaseTensor)
            True
            >>> cpu_tensor.data.device
            device(type='cpu')
        """
        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.cpu(), self.orig_shape)

    def numpy(self):
        """è¿”å›žæ•°æ®å·²è½¬æ¢ä¸º NumPy æ•°ç»„çš„å¯¹è±¡å‰¯æœ¬ã€‚

        Returns:
            (BaseTensor): `data` ä¸º NumPy æ•°ç»„çš„æ–°å®žä¾‹ã€‚

        Examples:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> orig_shape = (720, 1280)
            >>> base_tensor = BaseTensor(data, orig_shape)
            >>> numpy_tensor = base_tensor.numpy()
            >>> print(type(numpy_tensor.data))
            <class 'numpy.ndarray'>
        """
        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.numpy(), self.orig_shape)

    def cuda(self):
        """å°†å¼ é‡ç§»è‡³ GPU å†…å­˜ã€‚

        Returns:
            (BaseTensor): æ•°æ®å·²ç§»è‡³ GPU å†…å­˜çš„æ–° BaseTensor å®žä¾‹ã€‚

        Examples:
            >>> import torch
            >>> from ultralytics.engine.results import BaseTensor
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> gpu_tensor = base_tensor.cuda()
            >>> print(gpu_tensor.data.device)
            cuda:0
        """
        return self.__class__(torch.as_tensor(self.data).cuda(), self.orig_shape)

    def to(self, *args, **kwargs):
        """è¿”å›žå…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹çš„å¼ é‡å‰¯æœ¬ã€‚

        Args:
            *args (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„å¯å˜é•¿åº¦å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        Returns:
            (BaseTensor): æ•°æ®å·²ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œ/æˆ–æ•°æ®ç±»åž‹çš„æ–° BaseTensor å®žä¾‹ã€‚

        Examples:
            >>> base_tensor = BaseTensor(torch.randn(3, 4), orig_shape=(480, 640))
            >>> cuda_tensor = base_tensor.to("cuda")
            >>> float16_tensor = base_tensor.to(dtype=torch.float16)
        """
        return self.__class__(torch.as_tensor(self.data).to(*args, **kwargs), self.orig_shape)

    def __len__(self) -> int:
        """è¿”å›žåº•å±‚æ•°æ®å¼ é‡çš„é•¿åº¦ã€‚

        Returns:
            (int): æ•°æ®å¼ é‡ç¬¬ä¸€ç»´åº¦çš„å…ƒç´ æ•°é‡ã€‚

        Examples:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> len(base_tensor)
            2
        """
        return len(self.data)

    def __getitem__(self, idx):
        """è¿”å›žåŒ…å«æ•°æ®å¼ é‡æŒ‡å®šç´¢å¼•å…ƒç´ çš„æ–° BaseTensor å®žä¾‹ã€‚

        Args:
            idx (int | list[int] | torch.Tensor): è¦ä»Žæ•°æ®å¼ é‡ä¸­é€‰æ‹©çš„ç´¢å¼•æˆ–ç´¢å¼•é›†ã€‚

        Returns:
            (BaseTensor): åŒ…å«ç´¢å¼•æ•°æ®çš„æ–° BaseTensor å®žä¾‹ã€‚

        Examples:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> result = base_tensor[0]  # é€‰æ‹©ç¬¬ä¸€è¡Œ
            >>> print(result.data)
            tensor([1, 2, 3])
        """
        return self.__class__(self.data[idx], self.orig_shape)


class Results(SimpleClass, DataExportMixin):
    """ç”¨äºŽå­˜å‚¨å’Œæ“ä½œæŽ¨ç†ç»“æžœçš„ç±»ã€‚

    è¯¥ç±»ä¸ºå¤„ç†å„ç§ Ultralytics æ¨¡åž‹çš„æŽ¨ç†ç»“æžœæä¾›å…¨é¢çš„åŠŸèƒ½,
    åŒ…æ‹¬æ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»å’Œå§¿æ€ä¼°è®¡ã€‚æ”¯æŒå¯è§†åŒ–ã€æ•°æ®å¯¼å‡ºå’Œå„ç§åæ ‡è½¬æ¢ã€‚

    Attributes:
        orig_img (np.ndarray): ä½œä¸º numpy æ•°ç»„çš„åŽŸå§‹å›¾åƒã€‚
        orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        boxes (Boxes | None): æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ã€‚
        masks (Masks | None): åˆ†å‰²æŽ©ç ã€‚
        probs (Probs | None): åˆ†ç±»æ¦‚çŽ‡ã€‚
        keypoints (Keypoints | None): æ£€æµ‹åˆ°çš„å…³é”®ç‚¹ã€‚
        obb (OBB | None): æœ‰å‘è¾¹ç•Œæ¡†ã€‚
        speed (dict): åŒ…å«æŽ¨ç†é€Ÿåº¦ä¿¡æ¯çš„å­—å…¸ã€‚
        names (dict): å°†ç±»åˆ«ç´¢å¼•æ˜ å°„åˆ°ç±»åˆ«åç§°çš„å­—å…¸ã€‚
        path (str): è¾“å…¥å›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚
        save_dir (str | None): ä¿å­˜ç»“æžœçš„ç›®å½•ã€‚

    Methods:
        update: ä½¿ç”¨æ–°çš„æ£€æµ‹æ•°æ®æ›´æ–° Results å¯¹è±¡ã€‚
        cpu: è¿”å›žæ‰€æœ‰å¼ é‡å·²ç§»è‡³ CPU å†…å­˜çš„ Results å¯¹è±¡å‰¯æœ¬ã€‚
        numpy: å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„ã€‚
        cuda: å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡ç§»è‡³ GPU å†…å­˜ã€‚
        to: å°†æ‰€æœ‰å¼ é‡ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹ã€‚
        new: åˆ›å»ºå…·æœ‰ç›¸åŒå›¾åƒã€è·¯å¾„ã€åç§°å’Œé€Ÿåº¦å±žæ€§çš„æ–° Results å¯¹è±¡ã€‚
        plot: åœ¨è¾“å…¥ BGR å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æžœã€‚
        show: æ˜¾ç¤ºå¸¦æœ‰æ³¨é‡ŠæŽ¨ç†ç»“æžœçš„å›¾åƒã€‚
        save: å°†å¸¦æ³¨é‡Šçš„æŽ¨ç†ç»“æžœå›¾åƒä¿å­˜åˆ°æ–‡ä»¶ã€‚
        verbose: è¿”å›žç»“æžœä¸­æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—å­—ç¬¦ä¸²ã€‚
        save_txt: å°†æ£€æµ‹ç»“æžœä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ã€‚
        save_crop: å°†è£å‰ªçš„æ£€æµ‹å›¾åƒä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚
        summary: å°†æŽ¨ç†ç»“æžœè½¬æ¢ä¸ºæ‘˜è¦å­—å…¸ã€‚
        to_df: å°†æ£€æµ‹ç»“æžœè½¬æ¢ä¸º Polars DataFrameã€‚
        to_json: å°†æ£€æµ‹ç»“æžœè½¬æ¢ä¸º JSON æ ¼å¼ã€‚
        to_csv: å°†æ£€æµ‹ç»“æžœè½¬æ¢ä¸º CSV æ ¼å¼ã€‚

    Examples:
        >>> results = model("path/to/image.jpg")
        >>> result = results[0]  # èŽ·å–ç¬¬ä¸€ä¸ªç»“æžœ
        >>> boxes = result.boxes  # èŽ·å–ç¬¬ä¸€ä¸ªç»“æžœçš„è¾¹ç•Œæ¡†
        >>> masks = result.masks  # èŽ·å–ç¬¬ä¸€ä¸ªç»“æžœçš„æŽ©ç 
        >>> for result in results:
        >>>     result.plot()  # ç»˜åˆ¶æ£€æµ‹ç»“æžœ
    """

    def __init__(
        self,
        orig_img: np.ndarray,
        path: str,
        names: dict[int, str],
        boxes: torch.Tensor | None = None,
        masks: torch.Tensor | None = None,
        probs: torch.Tensor | None = None,
        keypoints: torch.Tensor | None = None,
        obb: torch.Tensor | None = None,
        speed: dict[str, float] | None = None,
    ) -> None:
        """åˆå§‹åŒ– Results ç±»,ç”¨äºŽå­˜å‚¨å’Œæ“ä½œæŽ¨ç†ç»“æžœã€‚

        Args:
            orig_img (np.ndarray): ä½œä¸º numpy æ•°ç»„çš„åŽŸå§‹å›¾åƒã€‚
            path (str): å›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚
            names (dict): ç±»åˆ«åç§°çš„å­—å…¸ã€‚
            boxes (torch.Tensor | None): æ¯ä¸ªæ£€æµ‹çš„è¾¹ç•Œæ¡†åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            masks (torch.Tensor | None): æ£€æµ‹æŽ©ç çš„ä¸‰ç»´å¼ é‡,å…¶ä¸­æ¯ä¸ªæŽ©ç éƒ½æ˜¯ä¸€ä¸ªäºŒå€¼å›¾åƒã€‚
            probs (torch.Tensor | None): åˆ†ç±»ä»»åŠ¡ä¸­æ¯ä¸ªç±»åˆ«çš„æ¦‚çŽ‡çš„ä¸€ç»´å¼ é‡ã€‚
            keypoints (torch.Tensor | None): æ¯ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            obb (torch.Tensor | None): æ¯ä¸ªæ£€æµ‹çš„æœ‰å‘è¾¹ç•Œæ¡†åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            speed (dict | None): åŒ…å«é¢„å¤„ç†ã€æŽ¨ç†å’ŒåŽå¤„ç†é€Ÿåº¦çš„å­—å…¸ (æ¯«ç§’/å›¾åƒ)ã€‚

        Notes:
            å¯¹äºŽé»˜è®¤å§¿æ€æ¨¡åž‹,äººä½“å§¿æ€ä¼°è®¡çš„å…³é”®ç‚¹ç´¢å¼•ä¸º:
            0: é¼»å­, 1: å·¦çœ¼, 2: å³çœ¼, 3: å·¦è€³, 4: å³è€³
            5: å·¦è‚©, 6: å³è‚©, 7: å·¦è‚˜, 8: å³è‚˜
            9: å·¦è…•, 10: å³è…•, 11: å·¦é«‹, 12: å³é«‹
            13: å·¦è†, 14: å³è†, 15: å·¦è¸, 16: å³è¸
        """
        self.orig_img = orig_img
        self.orig_shape = orig_img.shape[:2]
        self.boxes = Boxes(boxes, self.orig_shape) if boxes is not None else None  # native size boxes
        self.masks = Masks(masks, self.orig_shape) if masks is not None else None  # native size or imgsz masks
        self.probs = Probs(probs) if probs is not None else None
        self.keypoints = Keypoints(keypoints, self.orig_shape) if keypoints is not None else None
        self.obb = OBB(obb, self.orig_shape) if obb is not None else None
        self.speed = speed if speed is not None else {"preprocess": None, "inference": None, "postprocess": None}
        self.names = names
        self.path = path
        self.save_dir = None
        self._keys = "boxes", "masks", "probs", "keypoints", "obb"

    def __getitem__(self, idx):
        """è¿”å›žæŽ¨ç†ç»“æžœç‰¹å®šç´¢å¼•çš„ Results å¯¹è±¡ã€‚

        Args:
            idx (int | slice): è¦ä»Ž Results å¯¹è±¡æ£€ç´¢çš„ç´¢å¼•æˆ–åˆ‡ç‰‡ã€‚

        Returns:
            (Results): åŒ…å«æŒ‡å®šæŽ¨ç†ç»“æžœå­é›†çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")  # æ‰§è¡ŒæŽ¨ç†
            >>> single_result = results[0]  # èŽ·å–ç¬¬ä¸€ä¸ªç»“æžœ
            >>> subset_results = results[1:4]  # èŽ·å–ç»“æžœåˆ‡ç‰‡
        """
        return self._apply("__getitem__", idx)

    def __len__(self) -> int:
        """è¿”å›ž Results å¯¹è±¡ä¸­çš„æ£€æµ‹æ•°é‡ã€‚

        Returns:
            (int): æ£€æµ‹æ•°é‡,ç”± (masks, probs, keypoints æˆ– obb) ä¸­ç¬¬ä¸€ä¸ªéžç©ºå±žæ€§çš„é•¿åº¦ç¡®å®šã€‚

        Examples:
            >>> results = Results(orig_img, path, names, boxes=torch.rand(5, 4))
            >>> len(results)
            5
        """
        for k in self._keys:
            v = getattr(self, k)
            if v is not None:
                return len(v)

    def update(
        self,
        boxes: torch.Tensor | None = None,
        masks: torch.Tensor | None = None,
        probs: torch.Tensor | None = None,
        obb: torch.Tensor | None = None,
        keypoints: torch.Tensor | None = None,
    ):
        """ä½¿ç”¨æ–°çš„æ£€æµ‹æ•°æ®æ›´æ–° Results å¯¹è±¡ã€‚

        è¯¥æ–¹æ³•å…è®¸æ›´æ–° Results å¯¹è±¡çš„è¾¹ç•Œæ¡†ã€æŽ©ç ã€æ¦‚çŽ‡å’Œæœ‰å‘è¾¹ç•Œæ¡† (OBB)ã€‚
        å®ƒç¡®ä¿è¾¹ç•Œæ¡†è¢«è£å‰ªåˆ°åŽŸå§‹å›¾åƒå½¢çŠ¶ã€‚

        Args:
            boxes (torch.Tensor | None): å½¢çŠ¶ä¸º (N, 6) çš„å¼ é‡,åŒ…å«è¾¹ç•Œæ¡†åæ ‡å’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚
                æ ¼å¼ä¸º (x1, y1, x2, y2, conf, class)ã€‚
            masks (torch.Tensor | None): å½¢çŠ¶ä¸º (N, H, W) çš„å¼ é‡,åŒ…å«åˆ†å‰²æŽ©ç ã€‚
            probs (torch.Tensor | None): å½¢çŠ¶ä¸º (num_classes,) çš„å¼ é‡,åŒ…å«ç±»åˆ«æ¦‚çŽ‡ã€‚
            obb (torch.Tensor | None): å½¢çŠ¶ä¸º (N, 5) çš„å¼ é‡,åŒ…å«æœ‰å‘è¾¹ç•Œæ¡†åæ ‡ã€‚
            keypoints (torch.Tensor | None): å½¢çŠ¶ä¸º (N, 17, 3) çš„å¼ é‡,åŒ…å«å…³é”®ç‚¹ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> new_boxes = torch.tensor([[100, 100, 200, 200, 0.9, 0]])
            >>> results[0].update(boxes=new_boxes)
        """
        if boxes is not None:
            self.boxes = Boxes(ops.clip_boxes(boxes, self.orig_shape), self.orig_shape)
        if masks is not None:
            self.masks = Masks(masks, self.orig_shape)
        if probs is not None:
            self.probs = probs
        if obb is not None:
            self.obb = OBB(obb, self.orig_shape)
        if keypoints is not None:
            self.keypoints = Keypoints(keypoints, self.orig_shape)

    def _apply(self, fn: str, *args, **kwargs):
        """å¯¹æ‰€æœ‰éžç©ºå±žæ€§åº”ç”¨å‡½æ•°,å¹¶è¿”å›žå…·æœ‰ä¿®æ”¹å±žæ€§çš„æ–° Results å¯¹è±¡ã€‚

        è¯¥æ–¹æ³•ç”± .to(), .cuda(), .cpu() ç­‰æ–¹æ³•å†…éƒ¨è°ƒç”¨ã€‚

        Args:
            fn (str): è¦åº”ç”¨çš„å‡½æ•°åç§°ã€‚
            *args (Any): è¦ä¼ é€’ç»™å‡½æ•°çš„å¯å˜é•¿åº¦å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™å‡½æ•°çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        Returns:
            (Results): å±žæ€§å·²ç”±åº”ç”¨å‡½æ•°ä¿®æ”¹çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     result_cuda = result.cuda()
            ...     result_cpu = result.cpu()
        """
        r = self.new()
        for k in self._keys:
            v = getattr(self, k)
            if v is not None:
                setattr(r, k, getattr(v, fn)(*args, **kwargs))
        return r

    def cpu(self):
        """è¿”å›žæ‰€æœ‰å¼ é‡å·²ç§»è‡³ CPU å†…å­˜çš„ Results å¯¹è±¡å‰¯æœ¬ã€‚

        è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ–°çš„ Results å¯¹è±¡,å…¶æ‰€æœ‰å¼ é‡å±žæ€§ (boxes, masks, probs, keypoints, obb)
        å·²è½¬ç§»åˆ° CPU å†…å­˜ã€‚ç”¨äºŽå°†æ•°æ®ä»Ž GPU ç§»è‡³ CPU ä»¥è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†æˆ–ä¿å­˜ã€‚

        Returns:
            (Results): æ‰€æœ‰å¼ é‡å±žæ€§éƒ½åœ¨ CPU å†…å­˜ä¸Šçš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")  # æ‰§è¡ŒæŽ¨ç†
            >>> cpu_result = results[0].cpu()  # å°†ç¬¬ä¸€ä¸ªç»“æžœç§»è‡³ CPU
            >>> print(cpu_result.boxes.device)  # è¾“å‡º: cpu
        """
        return self._apply("cpu")

    def numpy(self):
        """å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„ã€‚

        Returns:
            (Results): æ‰€æœ‰å¼ é‡å·²è½¬æ¢ä¸º numpy æ•°ç»„çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> numpy_result = results[0].numpy()
            >>> type(numpy_result.boxes.data)
            <class 'numpy.ndarray'>

        Notes:
            è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ–°çš„ Results å¯¹è±¡,åŽŸå¯¹è±¡ä¿æŒä¸å˜ã€‚
            ç”¨äºŽä¸ŽåŸºäºŽ numpy çš„åº“äº’æ“ä½œæˆ–éœ€è¦åŸºäºŽ CPU çš„æ“ä½œæ—¶ã€‚
        """
        return self._apply("numpy")

    def cuda(self):
        """å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡ç§»è‡³ GPU å†…å­˜ã€‚

        Returns:
            (Results): æ‰€æœ‰å¼ é‡å·²ç§»è‡³ CUDA è®¾å¤‡çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> cuda_results = results[0].cuda()  # å°†ç¬¬ä¸€ä¸ªç»“æžœç§»è‡³ GPU
            >>> for result in results:
            ...     result_cuda = result.cuda()  # å°†æ¯ä¸ªç»“æžœç§»è‡³ GPU
        """
        return self._apply("cuda")

    def to(self, *args, **kwargs):
        """å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹ã€‚

        Args:
            *args (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„å¯å˜é•¿åº¦å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        Returns:
            (Results): æ‰€æœ‰å¼ é‡å·²ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> result_cuda = results[0].to("cuda")  # å°†ç¬¬ä¸€ä¸ªç»“æžœç§»è‡³ GPU
            >>> result_cpu = results[0].to("cpu")  # å°†ç¬¬ä¸€ä¸ªç»“æžœç§»è‡³ CPU
            >>> result_half = results[0].to(dtype=torch.float16)  # å°†ç¬¬ä¸€ä¸ªç»“æžœè½¬æ¢ä¸ºåŠç²¾åº¦
        """
        return self._apply("to", *args, **kwargs)

    def new(self):
        """åˆ›å»ºå…·æœ‰ç›¸åŒå›¾åƒã€è·¯å¾„ã€åç§°å’Œé€Ÿåº¦å±žæ€§çš„æ–° Results å¯¹è±¡ã€‚

        Returns:
            (Results): ä»ŽåŽŸå®žä¾‹å¤åˆ¶å±žæ€§çš„æ–° Results å¯¹è±¡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> new_result = results[0].new()
        """
        return Results(orig_img=self.orig_img, path=self.path, names=self.names, speed=self.speed)

    def plot(
        self,
        conf: bool = True,
        line_width: float | None = None,
        font_size: float | None = None,
        font: str = "Arial.ttf",
        pil: bool = False,
        img: np.ndarray | None = None,
        im_gpu: torch.Tensor | None = None,
        kpt_radius: int = 5,
        kpt_line: bool = True,
        labels: bool = True,
        boxes: bool = True,
        masks: bool = True,
        probs: bool = True,
        show: bool = False,
        save: bool = False,
        filename: str | None = None,
        color_mode: str = "class",
        txt_color: tuple[int, int, int] = (255, 255, 255),
    ) -> np.ndarray:
        """åœ¨è¾“å…¥ BGR å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æžœã€‚

        Args:
            conf (bool): æ˜¯å¦ç»˜åˆ¶æ£€æµ‹ç½®ä¿¡åº¦åˆ†æ•°ã€‚
            line_width (float | None): è¾¹ç•Œæ¡†çš„çº¿å®½ã€‚å¦‚æžœä¸º None,åˆ™æ ¹æ®å›¾åƒå¤§å°ç¼©æ”¾ã€‚
            font_size (float | None): æ–‡æœ¬çš„å­—ä½“å¤§å°ã€‚å¦‚æžœä¸º None,åˆ™æ ¹æ®å›¾åƒå¤§å°ç¼©æ”¾ã€‚
            font (str): ç”¨äºŽæ–‡æœ¬çš„å­—ä½“ã€‚
            pil (bool): æ˜¯å¦å°†å›¾åƒä½œä¸º PIL Image è¿”å›žã€‚
            img (np.ndarray | None): è¦ç»˜åˆ¶çš„å›¾åƒã€‚å¦‚æžœä¸º None,åˆ™ä½¿ç”¨åŽŸå§‹å›¾åƒã€‚
            im_gpu (torch.Tensor | None): GPU ä¸Šçš„å½’ä¸€åŒ–å›¾åƒ,ç”¨äºŽæ›´å¿«çš„æŽ©ç ç»˜åˆ¶ã€‚
            kpt_radius (int): ç»˜åˆ¶å…³é”®ç‚¹çš„åŠå¾„ã€‚
            kpt_line (bool): æ˜¯å¦ç»˜åˆ¶è¿žæŽ¥å…³é”®ç‚¹çš„çº¿ã€‚
            labels (bool): æ˜¯å¦ç»˜åˆ¶è¾¹ç•Œæ¡†çš„æ ‡ç­¾ã€‚
            boxes (bool): æ˜¯å¦ç»˜åˆ¶è¾¹ç•Œæ¡†ã€‚
            masks (bool): æ˜¯å¦ç»˜åˆ¶æŽ©ç ã€‚
            probs (bool): æ˜¯å¦ç»˜åˆ¶åˆ†ç±»æ¦‚çŽ‡ã€‚
            show (bool): æ˜¯å¦æ˜¾ç¤ºå¸¦æ³¨é‡Šçš„å›¾åƒã€‚
            save (bool): æ˜¯å¦ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾åƒã€‚
            filename (str | None): å¦‚æžœ save ä¸º True,ä¿å­˜å›¾åƒçš„æ–‡ä»¶åã€‚
            color_mode (str): æŒ‡å®šé¢œè‰²æ¨¡å¼,ä¾‹å¦‚ 'instance' æˆ– 'class'ã€‚
            txt_color (tuple[int, int, int]): åˆ†ç±»è¾“å‡ºçš„æ–‡æœ¬é¢œè‰²,BGR æ ¼å¼ã€‚

        Returns:
            (np.ndarray | PIL.Image.Image): å¸¦æ³¨é‡Šçš„å›¾åƒ,ä½œä¸º NumPy æ•°ç»„ (BGR) æˆ– PIL å›¾åƒ (RGB)(å¦‚æžœ `pil=True`)ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> for result in results:
            >>>     im = result.plot()
            >>>     im.show()
        """
        assert color_mode in {"instance", "class"}, f"Expected color_mode='instance' or 'class', not {color_mode}."
        if img is None and isinstance(self.orig_img, torch.Tensor):
            img = (self.orig_img[0].detach().permute(1, 2, 0).contiguous() * 255).byte().cpu().numpy()

        names = self.names
        is_obb = self.obb is not None
        pred_boxes, show_boxes = self.obb if is_obb else self.boxes, boxes
        pred_masks, show_masks = self.masks, masks
        pred_probs, show_probs = self.probs, probs
        annotator = Annotator(
            deepcopy(self.orig_img if img is None else img),
            line_width,
            font_size,
            font,
            pil or (pred_probs is not None and show_probs),  # Classify tasks default to pil=True
            example=names,
        )

        # Plot Segment results
        if pred_masks and show_masks:
            if im_gpu is None:
                img = LetterBox(pred_masks.shape[1:])(image=annotator.result())
                im_gpu = (
                    torch.as_tensor(img, dtype=torch.float16, device=pred_masks.data.device)
                    .permute(2, 0, 1)
                    .flip(0)
                    .contiguous()
                    / 255
                )
            idx = (
                pred_boxes.id
                if pred_boxes.is_track and color_mode == "instance"
                else pred_boxes.cls
                if pred_boxes and color_mode == "class"
                else reversed(range(len(pred_masks)))
            )
            annotator.masks(pred_masks.data, colors=[colors(x, True) for x in idx], im_gpu=im_gpu)

        # Plot Detect results
        if pred_boxes is not None and show_boxes:
            for i, d in enumerate(reversed(pred_boxes)):
                c, d_conf, id = int(d.cls), float(d.conf) if conf else None, int(d.id.item()) if d.is_track else None
                name = ("" if id is None else f"id:{id} ") + names[c]
                label = (f"{name} {d_conf:.2f}" if conf else name) if labels else None
                box = d.xyxyxyxy.squeeze() if is_obb else d.xyxy.squeeze()
                annotator.box_label(
                    box,
                    label,
                    color=colors(
                        c
                        if color_mode == "class"
                        else id
                        if id is not None
                        else i
                        if color_mode == "instance"
                        else None,
                        True,
                    ),
                )

        # Plot Classify results
        if pred_probs is not None and show_probs:
            text = "\n".join(f"{names[j] if names else j} {pred_probs.data[j]:.2f}" for j in pred_probs.top5)
            x = round(self.orig_shape[0] * 0.03)
            annotator.text([x, x], text, txt_color=txt_color, box_color=(64, 64, 64, 128))  # RGBA box

        # Plot Pose results
        if self.keypoints is not None:
            for i, k in enumerate(reversed(self.keypoints.data)):
                annotator.kpts(
                    k,
                    self.orig_shape,
                    radius=kpt_radius,
                    kpt_line=kpt_line,
                    kpt_color=colors(i, True) if color_mode == "instance" else None,
                )

        # Show results
        if show:
            annotator.show(self.path)

        # Save results
        if save:
            annotator.save(filename or f"results_{Path(self.path).name}")

        return annotator.result(pil)

    def show(self, *args, **kwargs):
        """æ˜¾ç¤ºå¸¦æœ‰æ³¨é‡ŠæŽ¨ç†ç»“æžœçš„å›¾åƒã€‚

        è¯¥æ–¹æ³•åœ¨åŽŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æžœå¹¶æ˜¾ç¤ºå®ƒã€‚è¿™æ˜¯ç›´æŽ¥å¯è§†åŒ–æ¨¡åž‹é¢„æµ‹çš„ä¾¿æ·æ–¹æ³•ã€‚

        Args:
            *args (Any): è¦ä¼ é€’ç»™ `plot()` æ–¹æ³•çš„å¯å˜é•¿åº¦å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™ `plot()` æ–¹æ³•çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> results[0].show()  # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æžœ
            >>> for result in results:
            >>>     result.show()  # æ˜¾ç¤ºæ‰€æœ‰ç»“æžœ
        """
        self.plot(show=True, *args, **kwargs)

    def save(self, filename: str | None = None, *args, **kwargs) -> str:
        """å°†å¸¦æ³¨é‡Šçš„æŽ¨ç†ç»“æžœå›¾åƒä¿å­˜åˆ°æ–‡ä»¶ã€‚

        è¯¥æ–¹æ³•åœ¨åŽŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æžœå¹¶å°†å¸¦æ³¨é‡Šçš„å›¾åƒä¿å­˜åˆ°æ–‡ä»¶ã€‚
        å®ƒåˆ©ç”¨ `plot` æ–¹æ³•ç”Ÿæˆå¸¦æ³¨é‡Šçš„å›¾åƒ,ç„¶åŽå°†å…¶ä¿å­˜åˆ°æŒ‡å®šçš„æ–‡ä»¶åã€‚

        Args:
            filename (str | Path | None): ä¿å­˜å¸¦æ³¨é‡Šå›¾åƒçš„æ–‡ä»¶åã€‚å¦‚æžœä¸º None,
                åˆ™æ ¹æ®åŽŸå§‹å›¾åƒè·¯å¾„ç”Ÿæˆé»˜è®¤æ–‡ä»¶åã€‚
            *args (Any): è¦ä¼ é€’ç»™ `plot` æ–¹æ³•çš„å¯å˜é•¿åº¦å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™ `plot` æ–¹æ³•çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        Returns:
            (str): å›¾åƒä¿å­˜çš„æ–‡ä»¶åã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            >>>     result.save("annotated_image.jpg")
            >>> # æˆ–ä½¿ç”¨è‡ªå®šä¹‰ç»˜å›¾å‚æ•°
            >>> for result in results:
            >>>     result.save("annotated_image.jpg", conf=False, line_width=2)
        """
        if not filename:
            filename = f"results_{Path(self.path).name}"
        self.plot(save=True, filename=filename, *args, **kwargs)
        return filename

    def verbose(self) -> str:
        """è¿”å›žç»“æžœä¸­æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—å­—ç¬¦ä¸²,è¯¦ç»†è¯´æ˜Žæ£€æµ‹å’Œåˆ†ç±»ç»“æžœã€‚

        è¯¥æ–¹æ³•ç”Ÿæˆä¸€ä¸ªäººç±»å¯è¯»çš„å­—ç¬¦ä¸²,æ€»ç»“æ£€æµ‹å’Œåˆ†ç±»ç»“æžœã€‚
        å®ƒåŒ…æ‹¬æ¯ä¸ªç±»åˆ«çš„æ£€æµ‹æ•°é‡å’Œåˆ†ç±»ä»»åŠ¡çš„æœ€é«˜æ¦‚çŽ‡ã€‚

        Returns:
            (str): åŒ…å«ç»“æžœæ‘˜è¦çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚å¯¹äºŽæ£€æµ‹ä»»åŠ¡,å®ƒåŒ…æ‹¬æ¯ä¸ªç±»åˆ«çš„æ£€æµ‹æ•°é‡ã€‚
                å¯¹äºŽåˆ†ç±»ä»»åŠ¡,å®ƒåŒ…æ‹¬å‰ 5 ä¸ªç±»åˆ«æ¦‚çŽ‡ã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            >>>     print(result.verbose())
            2 persons, 1 car, 3 traffic lights,
            dog 0.92, cat 0.78, horse 0.64,

        Notes:
            - å¦‚æžœæ²¡æœ‰æ£€æµ‹,è¯¥æ–¹æ³•å¯¹æ£€æµ‹ä»»åŠ¡è¿”å›ž "(no detections), "ã€‚
            - å¯¹äºŽåˆ†ç±»ä»»åŠ¡,å®ƒè¿”å›žå‰ 5 ä¸ªç±»åˆ«æ¦‚çŽ‡åŠå…¶å¯¹åº”çš„ç±»åˆ«åç§°ã€‚
            - è¿”å›žçš„å­—ç¬¦ä¸²ä»¥é€—å·åˆ†éš”,å¹¶ä»¥é€—å·å’Œç©ºæ ¼ç»“å°¾ã€‚
        """
        boxes = self.obb if self.obb is not None else self.boxes
        if len(self) == 0:
            return "" if self.probs is not None else "(no detections), "
        if self.probs is not None:
            return f"{', '.join(f'{self.names[j]} {self.probs.data[j]:.2f}' for j in self.probs.top5)}, "
        if boxes:
            counts = boxes.cls.int().bincount()
            return "".join(f"{n} {self.names[i]}{'s' * (n > 1)}, " for i, n in enumerate(counts) if n > 0)

    def save_txt(self, txt_file: str | Path, save_conf: bool = False) -> str:
        """å°†æ£€æµ‹ç»“æžœä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ã€‚

        Args:
            txt_file (str | Path): è¾“å‡ºæ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚
            save_conf (bool): æ˜¯å¦åœ¨è¾“å‡ºä¸­åŒ…å«ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        Returns:
            (str): ä¿å­˜çš„æ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚

        Examples:
            >>> from ultralytics import YOLO
            >>> model = YOLO("yolo11n.pt")
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            >>>     result.save_txt("output.txt")

        Notes:
            - æ–‡ä»¶å°†åŒ…å«æ¯ä¸ªæ£€æµ‹æˆ–åˆ†ç±»çš„ä¸€è¡Œ,å…·æœ‰ä»¥ä¸‹ç»“æž„:
              - å¯¹äºŽæ£€æµ‹: `class confidence x_center y_center width height`
              - å¯¹äºŽåˆ†ç±»: `confidence class_name`
              - å¯¹äºŽæŽ©ç å’Œå…³é”®ç‚¹,ç‰¹å®šæ ¼å¼ä¼šç›¸åº”å˜åŒ–ã€‚
            - å¦‚æžœè¾“å‡ºç›®å½•ä¸å­˜åœ¨,è¯¥å‡½æ•°å°†åˆ›å»ºå®ƒã€‚
            - å¦‚æžœ save_conf ä¸º False,ç½®ä¿¡åº¦åˆ†æ•°å°†ä»Žè¾“å‡ºä¸­æŽ’é™¤ã€‚
            - ä¸ä¼šè¦†ç›–æ–‡ä»¶çš„çŽ°æœ‰å†…å®¹;æ–°ç»“æžœå°†è¢«è¿½åŠ ã€‚
        """
        is_obb = self.obb is not None
        boxes = self.obb if is_obb else self.boxes
        masks = self.masks
        probs = self.probs
        kpts = self.keypoints
        texts = []
        if probs is not None:
            # Classify
            [texts.append(f"{probs.data[j]:.2f} {self.names[j]}") for j in probs.top5]
        elif boxes:
            # Detect/segment/pose
            for j, d in enumerate(boxes):
                c, conf, id = int(d.cls), float(d.conf), int(d.id.item()) if d.is_track else None
                line = (c, *(d.xyxyxyxyn.view(-1) if is_obb else d.xywhn.view(-1)))
                if masks:
                    seg = masks[j].xyn[0].copy().reshape(-1)  # reversed mask.xyn, (n,2) to (n*2)
                    line = (c, *seg)
                if kpts is not None:
                    kpt = torch.cat((kpts[j].xyn, kpts[j].conf[..., None]), 2) if kpts[j].has_visible else kpts[j].xyn
                    line += (*kpt.reshape(-1).tolist(),)
                line += (conf,) * save_conf + (() if id is None else (id,))
                texts.append(("%g " * len(line)).rstrip() % line)

        if texts:
            Path(txt_file).parent.mkdir(parents=True, exist_ok=True)  # make directory
            with open(txt_file, "a", encoding="utf-8") as f:
                f.writelines(text + "\n" for text in texts)

        return str(txt_file)

    def save_crop(self, save_dir: str | Path, file_name: str | Path = Path("im.jpg")):
        """å°†è£å‰ªçš„æ£€æµ‹å›¾åƒä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹åˆ°çš„å¯¹è±¡çš„è£å‰ªå›¾åƒä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚æ¯ä¸ªè£å‰ªå›¾åƒéƒ½ä¿å­˜åœ¨
        ä»¥å¯¹è±¡ç±»åˆ«å‘½åçš„å­ç›®å½•ä¸­,æ–‡ä»¶ååŸºäºŽè¾“å…¥çš„ file_nameã€‚

        Args:
            save_dir (str | Path): ä¿å­˜è£å‰ªå›¾åƒçš„ç›®å½•è·¯å¾„ã€‚
            file_name (str | Path): ä¿å­˜çš„è£å‰ªå›¾åƒçš„åŸºæœ¬æ–‡ä»¶åã€‚

        Examples:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            >>>     result.save_crop(save_dir="path/to/crops", file_name="detection")

        Notes:
            - è¯¥æ–¹æ³•ä¸æ”¯æŒåˆ†ç±»æˆ–æœ‰å‘è¾¹ç•Œæ¡† (OBB) ä»»åŠ¡ã€‚
            - è£å‰ªå›¾åƒä¿å­˜ä¸º 'save_dir/class_name/file_name.jpg'ã€‚
            - å¦‚æžœå­ç›®å½•ä¸å­˜åœ¨,è¯¥æ–¹æ³•å°†åˆ›å»ºå¿…è¦çš„å­ç›®å½•ã€‚
            - åœ¨è£å‰ªå‰å¤åˆ¶åŽŸå§‹å›¾åƒä»¥é¿å…ä¿®æ”¹åŽŸå§‹å›¾åƒã€‚
        """
        if self.probs is not None:
            LOGGER.warning("Classify task does not support `save_crop`.")
            return
        if self.obb is not None:
            LOGGER.warning("OBB task does not support `save_crop`.")
            return
        for d in self.boxes:
            save_one_box(
                d.xyxy,
                self.orig_img.copy(),
                file=Path(save_dir) / self.names[int(d.cls)] / Path(file_name).with_suffix(".jpg"),
                BGR=True,
            )

    def summary(self, normalize: bool = False, decimals: int = 5) -> list[dict[str, Any]]:
        """å°†æŽ¨ç†ç»“æžœè½¬æ¢ä¸ºæ‘˜è¦å­—å…¸,å¯é€‰æ‹©å¯¹è¾¹ç•Œæ¡†åæ ‡è¿›è¡Œå½’ä¸€åŒ–ã€‚

        è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ£€æµ‹å­—å…¸åˆ—è¡¨,æ¯ä¸ªå­—å…¸åŒ…å«æœ‰å…³å•ä¸ªæ£€æµ‹æˆ–åˆ†ç±»ç»“æžœçš„ä¿¡æ¯ã€‚
        å¯¹äºŽåˆ†ç±»ä»»åŠ¡,å®ƒè¿”å›žæœ€é«˜ç±»åˆ«åŠå…¶ç½®ä¿¡åº¦ã€‚å¯¹äºŽæ£€æµ‹ä»»åŠ¡,å®ƒåŒ…æ‹¬ç±»åˆ«ä¿¡æ¯ã€
        è¾¹ç•Œæ¡†åæ ‡,ä»¥åŠå¯é€‰çš„æŽ©ç ç‰‡æ®µå’Œå…³é”®ç‚¹ã€‚

        Args:
            normalize (bool): æ˜¯å¦æ ¹æ®å›¾åƒå°ºå¯¸å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡ã€‚
            decimals (int): è¾“å‡ºå€¼è¦èˆå…¥åˆ°çš„å°æ•°ä½æ•°ã€‚

        Returns:
            (list[dict[str, Any]]): å­—å…¸åˆ—è¡¨,æ¯ä¸ªå­—å…¸åŒ…å«å•ä¸ªæ£€æµ‹æˆ–åˆ†ç±»ç»“æžœçš„æ‘˜è¦ä¿¡æ¯ã€‚
                æ¯ä¸ªå­—å…¸çš„ç»“æž„æ ¹æ®ä»»åŠ¡ç±»åž‹(åˆ†ç±»æˆ–æ£€æµ‹)å’Œå¯ç”¨ä¿¡æ¯(è¾¹ç•Œæ¡†ã€æŽ©ç ã€å…³é”®ç‚¹)è€Œå˜åŒ–ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> for result in results:
            >>>     summary = result.summary()
            >>>     print(summary)
        """
        # Create list of detection dictionaries
        results = []
        if self.probs is not None:
            class_id = self.probs.top1
            results.append(
                {
                    "name": self.names[class_id],
                    "class": class_id,
                    "confidence": round(self.probs.top1conf.item(), decimals),
                }
            )
            return results

        is_obb = self.obb is not None
        data = self.obb if is_obb else self.boxes
        h, w = self.orig_shape if normalize else (1, 1)
        for i, row in enumerate(data):  # xyxy, track_id if tracking, conf, class_id
            class_id, conf = int(row.cls), round(row.conf.item(), decimals)
            box = (row.xyxyxyxy if is_obb else row.xyxy).squeeze().reshape(-1, 2).tolist()
            xy = {}
            for j, b in enumerate(box):
                xy[f"x{j + 1}"] = round(b[0] / w, decimals)
                xy[f"y{j + 1}"] = round(b[1] / h, decimals)
            result = {"name": self.names[class_id], "class": class_id, "confidence": conf, "box": xy}
            if data.is_track:
                result["track_id"] = int(row.id.item())  # track ID
            if self.masks:
                result["segments"] = {
                    "x": (self.masks.xy[i][:, 0] / w).round(decimals).tolist(),
                    "y": (self.masks.xy[i][:, 1] / h).round(decimals).tolist(),
                }
            if self.keypoints is not None:
                x, y, visible = self.keypoints[i].data[0].cpu().unbind(dim=1)  # torch Tensor
                result["keypoints"] = {
                    "x": (x / w).numpy().round(decimals).tolist(),  # decimals named argument required
                    "y": (y / h).numpy().round(decimals).tolist(),
                    "visible": visible.numpy().round(decimals).tolist(),
                }
            results.append(result)

        return results


class Boxes(BaseTensor):
    """ç”¨äºŽç®¡ç†å’Œæ“ä½œæ£€æµ‹æ¡†çš„ç±»ã€‚

    è¯¥ç±»ä¸ºå¤„ç†æ£€æµ‹æ¡†æä¾›å…¨é¢çš„åŠŸèƒ½,åŒ…æ‹¬å…¶åæ ‡ã€ç½®ä¿¡åº¦åˆ†æ•°ã€ç±»åˆ«æ ‡ç­¾å’Œå¯é€‰çš„è·Ÿè¸ª IDã€‚
    å®ƒæ”¯æŒå„ç§è¾¹ç•Œæ¡†æ ¼å¼,å¹¶æä¾›åœ¨ä¸åŒåæ ‡ç³»ä¹‹é—´è½»æ¾æ“ä½œå’Œè½¬æ¢çš„æ–¹æ³•ã€‚

    Attributes:
        data (torch.Tensor | np.ndarray): åŒ…å«æ£€æµ‹æ¡†å’Œå…³è”æ•°æ®çš„åŽŸå§‹å¼ é‡ã€‚
        orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚
        is_track (bool): æŒ‡ç¤ºè¾¹ç•Œæ¡†æ•°æ®ä¸­æ˜¯å¦åŒ…å«è·Ÿè¸ª IDã€‚
        xyxy (torch.Tensor | np.ndarray): [x1, y1, x2, y2] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚
        conf (torch.Tensor | np.ndarray): æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        cls (torch.Tensor | np.ndarray): æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç±»åˆ«æ ‡ç­¾ã€‚
        id (torch.Tensor | None): æ¯ä¸ªè¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID(å¦‚æžœå¯ç”¨)ã€‚
        xywh (torch.Tensor | np.ndarray): [x, y, width, height] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚
        xyxyn (torch.Tensor | np.ndarray): ç›¸å¯¹äºŽ orig_shape å½’ä¸€åŒ–çš„ [x1, y1, x2, y2] è¾¹ç•Œæ¡†ã€‚
        xywhn (torch.Tensor | np.ndarray): ç›¸å¯¹äºŽ orig_shape å½’ä¸€åŒ–çš„ [x, y, width, height] è¾¹ç•Œæ¡†ã€‚

    Methods:
        cpu: è¿”å›žæ‰€æœ‰å¼ é‡åœ¨ CPU å†…å­˜ä¸Šçš„å¯¹è±¡å‰¯æœ¬ã€‚
        numpy: è¿”å›žæ‰€æœ‰å¼ é‡ä¸º numpy æ•°ç»„çš„å¯¹è±¡å‰¯æœ¬ã€‚
        cuda: è¿”å›žæ‰€æœ‰å¼ é‡åœ¨ GPU å†…å­˜ä¸Šçš„å¯¹è±¡å‰¯æœ¬ã€‚
        to: è¿”å›žå¼ é‡åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹ä¸Šçš„å¯¹è±¡å‰¯æœ¬ã€‚

    Examples:
        >>> import torch
        >>> boxes_data = torch.tensor([[100, 50, 150, 100, 0.9, 0], [200, 150, 300, 250, 0.8, 1]])
        >>> orig_shape = (480, 640)  # é«˜åº¦, å®½åº¦
        >>> boxes = Boxes(boxes_data, orig_shape)
        >>> print(boxes.xyxy)
        >>> print(boxes.conf)
        >>> print(boxes.cls)
        >>> print(boxes.xywhn)
    """

    def __init__(self, boxes: torch.Tensor | np.ndarray, orig_shape: tuple[int, int]) -> None:
        """ä½¿ç”¨æ£€æµ‹æ¡†æ•°æ®å’ŒåŽŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ– Boxes ç±»ã€‚

        è¯¥ç±»ç®¡ç†æ£€æµ‹æ¡†,æä¾›å¯¹è¾¹ç•Œæ¡†åæ ‡ã€ç½®ä¿¡åº¦åˆ†æ•°ã€ç±»åˆ«æ ‡è¯†ç¬¦å’Œå¯é€‰è·Ÿè¸ª ID çš„è½»æ¾è®¿é—®å’Œæ“ä½œã€‚
        å®ƒæ”¯æŒè¾¹ç•Œæ¡†åæ ‡çš„å¤šç§æ ¼å¼,åŒ…æ‹¬ç»å¯¹å’Œå½’ä¸€åŒ–å½¢å¼ã€‚

        Args:
            boxes (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (num_boxes, 6) æˆ– (num_boxes, 7) çš„å¼ é‡æˆ– numpy æ•°ç»„ã€‚
                åˆ—åº”åŒ…å« [x1, y1, x2, y2, (å¯é€‰) track_id, confidence, class]ã€‚
            orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚ç”¨äºŽå½’ä¸€åŒ–ã€‚
        """
        if boxes.ndim == 1:
            boxes = boxes[None, :]
        n = boxes.shape[-1]
        assert n in {6, 7}, f"expected 6 or 7 values but got {n}"  # xyxy, track_id, conf, cls
        super().__init__(boxes, orig_shape)
        self.is_track = n == 7
        self.orig_shape = orig_shape

    @property
    def xyxy(self) -> torch.Tensor | np.ndarray:
        """è¿”å›ž [x1, y1, x2, y2] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚

        Returns:
            (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (n, 4) çš„å¼ é‡æˆ– numpy æ•°ç»„,åŒ…å« [x1, y1, x2, y2] æ ¼å¼çš„
                è¾¹ç•Œæ¡†åæ ‡,å…¶ä¸­ n æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> boxes = results[0].boxes
            >>> xyxy = boxes.xyxy
            >>> print(xyxy)
        """
        return self.data[:, :4]

    @property
    def conf(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žæ¯ä¸ªæ£€æµ‹æ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å«æ¯ä¸ªæ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°çš„ä¸€ç»´å¼ é‡æˆ–æ•°ç»„,
                å½¢çŠ¶ä¸º (N,),å…¶ä¸­ N æ˜¯æ£€æµ‹æ•°é‡ã€‚

        Examples:
            >>> boxes = Boxes(torch.tensor([[10, 20, 30, 40, 0.9, 0]]), orig_shape=(100, 100))
            >>> conf_scores = boxes.conf
            >>> print(conf_scores)
            tensor([0.9000])
        """
        return self.data[:, -2]

    @property
    def cls(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žè¡¨ç¤ºæ¯ä¸ªè¾¹ç•Œæ¡†ç±»åˆ«é¢„æµ‹çš„ç±»åˆ« ID å¼ é‡ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å«æ¯ä¸ªæ£€æµ‹æ¡†çš„ç±»åˆ« ID çš„å¼ é‡æˆ– numpy æ•°ç»„ã€‚
                å½¢çŠ¶ä¸º (N,),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> boxes = results[0].boxes
            >>> class_ids = boxes.cls
            >>> print(class_ids)  # tensor([0., 2., 1.])
        """
        return self.data[:, -1]

    @property
    def id(self) -> torch.Tensor | np.ndarray | None:
        """è¿”å›žæ¯ä¸ªæ£€æµ‹æ¡†çš„è·Ÿè¸ª ID(å¦‚æžœå¯ç”¨)ã€‚

        Returns:
            (torch.Tensor | None): å¦‚æžœå¯ç”¨è·Ÿè¸ª,åˆ™åŒ…å«æ¯ä¸ªè¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID çš„å¼ é‡,å¦åˆ™ä¸º Noneã€‚
                å½¢çŠ¶ä¸º (N,),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> results = model.track("path/to/video.mp4")
            >>> for result in results:
            ...     boxes = result.boxes
            ...     if boxes.is_track:
            ...         track_ids = boxes.id
            ...         print(f"Tracking IDs: {track_ids}")
            ...     else:
            ...         print("Tracking is not enabled for these boxes.")

        Notes:
            - ä»…å½“å¯ç”¨è·Ÿè¸ªæ—¶(å³ `is_track` ä¸º True æ—¶)æ­¤å±žæ€§æ‰å¯ç”¨ã€‚
            - è·Ÿè¸ª ID é€šå¸¸ç”¨äºŽåœ¨è§†é¢‘åˆ†æžä¸­å…³è”å¤šä¸ªå¸§ä¹‹é—´çš„æ£€æµ‹ã€‚
        """
        return self.data[:, -3] if self.is_track else None

    @property
    @lru_cache(maxsize=2)
    def xywh(self) -> torch.Tensor | np.ndarray:
        """å°†è¾¹ç•Œæ¡†ä»Ž [x1, y1, x2, y2] æ ¼å¼è½¬æ¢ä¸º [x, y, width, height] æ ¼å¼ã€‚

        Returns:
            (torch.Tensor | np.ndarray): [x_center, y_center, width, height] æ ¼å¼çš„è¾¹ç•Œæ¡†,å…¶ä¸­ x_center, y_center
                æ˜¯è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„åæ ‡,width, height æ˜¯è¾¹ç•Œæ¡†çš„å°ºå¯¸,è¿”å›žå¼ é‡çš„å½¢çŠ¶ä¸º (N, 4),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> boxes = Boxes(torch.tensor([[100, 50, 150, 100], [200, 150, 300, 250]]), orig_shape=(480, 640))
            >>> xywh = boxes.xywh
            >>> print(xywh)
            tensor([[125.0000,  75.0000,  50.0000,  50.0000],
                    [250.0000, 200.0000, 100.0000, 100.0000]])
        """
        return ops.xyxy2xywh(self.xyxy)

    @property
    @lru_cache(maxsize=2)
    def xyxyn(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå¤§å°å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†åæ ‡ã€‚

        è¯¥å±žæ€§è®¡ç®—å¹¶è¿”å›ž [x1, y1, x2, y2] æ ¼å¼çš„è¾¹ç•Œæ¡†åæ ‡,
        åŸºäºŽåŽŸå§‹å›¾åƒå°ºå¯¸å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ã€‚

        Returns:
            (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (N, 4) çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡,å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚
                æ¯è¡ŒåŒ…å«å½’ä¸€åŒ–åˆ° [0, 1] çš„ [x1, y1, x2, y2] å€¼ã€‚

        Examples:
            >>> boxes = Boxes(torch.tensor([[100, 50, 300, 400, 0.9, 0]]), orig_shape=(480, 640))
            >>> normalized = boxes.xyxyn
            >>> print(normalized)
            tensor([[0.1562, 0.1042, 0.4688, 0.8333]])
        """
        xyxy = self.xyxy.clone() if isinstance(self.xyxy, torch.Tensor) else np.copy(self.xyxy)
        xyxy[..., [0, 2]] /= self.orig_shape[1]
        xyxy[..., [1, 3]] /= self.orig_shape[0]
        return xyxy

    @property
    @lru_cache(maxsize=2)
    def xywhn(self) -> torch.Tensor | np.ndarray:
        """è¿”å›ž [x, y, width, height] æ ¼å¼çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†ã€‚

        è¯¥å±žæ€§è®¡ç®—å¹¶è¿”å›ž [x_center, y_center, width, height] æ ¼å¼çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡,
        å…¶ä¸­æ‰€æœ‰å€¼éƒ½ç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå°ºå¯¸ã€‚

        Returns:
            (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (N, 4) çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†,å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚
                æ¯è¡ŒåŒ…å«åŸºäºŽåŽŸå§‹å›¾åƒå°ºå¯¸å½’ä¸€åŒ–åˆ° [0, 1] çš„ [x_center, y_center, width, height] å€¼ã€‚

        Examples:
            >>> boxes = Boxes(torch.tensor([[100, 50, 150, 100, 0.9, 0]]), orig_shape=(480, 640))
            >>> normalized = boxes.xywhn
            >>> print(normalized)
            tensor([[0.1953, 0.1562, 0.0781, 0.1042]])
        """
        xywh = ops.xyxy2xywh(self.xyxy)
        xywh[..., [0, 2]] /= self.orig_shape[1]
        xywh[..., [1, 3]] /= self.orig_shape[0]
        return xywh


class Masks(BaseTensor):
    """ç”¨äºŽå­˜å‚¨å’Œæ“ä½œæ£€æµ‹æŽ©ç çš„ç±»ã€‚

    è¯¥ç±»æ‰©å±• BaseTensor å¹¶æä¾›å¤„ç†åˆ†å‰²æŽ©ç çš„åŠŸèƒ½,åŒ…æ‹¬åœ¨åƒç´ åæ ‡å’Œå½’ä¸€åŒ–åæ ‡ä¹‹é—´è½¬æ¢çš„æ–¹æ³•ã€‚

    Attributes:
        data (torch.Tensor | np.ndarray): åŒ…å«æŽ©ç æ•°æ®çš„åŽŸå§‹å¼ é‡æˆ–æ•°ç»„ã€‚
        orig_shape (tuple): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        xy (list[np.ndarray]): åƒç´ åæ ‡ä¸­çš„ç‰‡æ®µåˆ—è¡¨ã€‚
        xyn (list[np.ndarray]): å½’ä¸€åŒ–ç‰‡æ®µçš„åˆ—è¡¨ã€‚

    Methods:
        cpu: è¿”å›žæŽ©ç å¼ é‡åœ¨ CPU å†…å­˜ä¸Šçš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        numpy: è¿”å›žæŽ©ç å¼ é‡ä¸º numpy æ•°ç»„çš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        cuda: è¿”å›žæŽ©ç å¼ é‡åœ¨ GPU å†…å­˜ä¸Šçš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        to: è¿”å›žæŽ©ç å¼ é‡åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹ä¸Šçš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚

    Examples:
        >>> masks_data = torch.rand(1, 160, 160)
        >>> orig_shape = (720, 1280)
        >>> masks = Masks(masks_data, orig_shape)
        >>> pixel_coords = masks.xy
        >>> normalized_coords = masks.xyn
    """

    def __init__(self, masks: torch.Tensor | np.ndarray, orig_shape: tuple[int, int]) -> None:
        """ä½¿ç”¨æ£€æµ‹æŽ©ç æ•°æ®å’ŒåŽŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ– Masks ç±»ã€‚

        Args:
            masks (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (num_masks, height, width) çš„æ£€æµ‹æŽ©ç ã€‚
            orig_shape (tuple): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚ç”¨äºŽå½’ä¸€åŒ–ã€‚
        """
        if masks.ndim == 2:
            masks = masks[None, :]
        super().__init__(masks, orig_shape)

    @property
    @lru_cache(maxsize=1)
    def xyn(self) -> list[np.ndarray]:
        """è¿”å›žåˆ†å‰²æŽ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚

        è¯¥å±žæ€§è®¡ç®—å¹¶ç¼“å­˜åˆ†å‰²æŽ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚åæ ‡ç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå½¢çŠ¶è¿›è¡Œå½’ä¸€åŒ–ã€‚

        Returns:
            (list[np.ndarray]): numpy æ•°ç»„åˆ—è¡¨,å…¶ä¸­æ¯ä¸ªæ•°ç»„åŒ…å«å•ä¸ªåˆ†å‰²æŽ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚
                æ¯ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (N, 2),å…¶ä¸­ N æ˜¯æŽ©ç è½®å»“ä¸­çš„ç‚¹æ•°ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> masks = results[0].masks
            >>> normalized_coords = masks.xyn
            >>> print(normalized_coords[0])  # ç¬¬ä¸€ä¸ªæŽ©ç çš„å½’ä¸€åŒ–åæ ‡
        """
        return [
            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=True)
            for x in ops.masks2segments(self.data)
        ]

    @property
    @lru_cache(maxsize=1)
    def xy(self) -> list[np.ndarray]:
        """è¿”å›žæŽ©ç å¼ é‡ä¸­æ¯ä¸ªç‰‡æ®µçš„ [x, y] åƒç´ åæ ‡ã€‚

        è¯¥å±žæ€§è®¡ç®—å¹¶è¿”å›ž Masks å¯¹è±¡ä¸­æ¯ä¸ªåˆ†å‰²æŽ©ç çš„åƒç´ åæ ‡åˆ—è¡¨ã€‚
        åæ ‡è¢«ç¼©æ”¾ä»¥åŒ¹é…åŽŸå§‹å›¾åƒå°ºå¯¸ã€‚

        Returns:
            (list[np.ndarray]): numpy æ•°ç»„åˆ—è¡¨,å…¶ä¸­æ¯ä¸ªæ•°ç»„åŒ…å«å•ä¸ªåˆ†å‰²æŽ©ç çš„ [x, y] åƒç´ åæ ‡ã€‚
                æ¯ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (N, 2),å…¶ä¸­ N æ˜¯ç‰‡æ®µä¸­çš„ç‚¹æ•°ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> masks = results[0].masks
            >>> xy_coords = masks.xy
            >>> print(len(xy_coords))  # æŽ©ç æ•°é‡
            >>> print(xy_coords[0].shape)  # ç¬¬ä¸€ä¸ªæŽ©ç åæ ‡çš„å½¢çŠ¶
        """
        return [
            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=False)
            for x in ops.masks2segments(self.data)
        ]


class Keypoints(BaseTensor):
    """ç”¨äºŽå­˜å‚¨å’Œæ“ä½œæ£€æµ‹å…³é”®ç‚¹çš„ç±»ã€‚

    è¯¥ç±»å°è£…äº†å¤„ç†å…³é”®ç‚¹æ•°æ®çš„åŠŸèƒ½,åŒ…æ‹¬åæ ‡æ“ä½œã€å½’ä¸€åŒ–å’Œç½®ä¿¡åº¦å€¼ã€‚
    å®ƒæ”¯æŒå¸¦æœ‰å¯é€‰å¯è§æ€§ä¿¡æ¯çš„å…³é”®ç‚¹æ£€æµ‹ç»“æžœã€‚

    Attributes:
        data (torch.Tensor): åŒ…å«å…³é”®ç‚¹æ•°æ®çš„åŽŸå§‹å¼ é‡ã€‚
        orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚
        has_visible (bool): æŒ‡ç¤ºå…³é”®ç‚¹æ˜¯å¦æœ‰å¯è§æ€§ä¿¡æ¯ã€‚
        xy (torch.Tensor): [x, y] æ ¼å¼çš„å…³é”®ç‚¹åæ ‡ã€‚
        xyn (torch.Tensor): [x, y] æ ¼å¼çš„å½’ä¸€åŒ–å…³é”®ç‚¹åæ ‡,ç›¸å¯¹äºŽ orig_shapeã€‚
        conf (torch.Tensor): æ¯ä¸ªå…³é”®ç‚¹çš„ç½®ä¿¡åº¦å€¼(å¦‚æžœå¯ç”¨)ã€‚

    Methods:
        cpu: è¿”å›žå…³é”®ç‚¹å¼ é‡åœ¨ CPU å†…å­˜ä¸Šçš„å‰¯æœ¬ã€‚
        numpy: è¿”å›žå…³é”®ç‚¹å¼ é‡çš„ numpy æ•°ç»„å‰¯æœ¬ã€‚
        cuda: è¿”å›žå…³é”®ç‚¹å¼ é‡åœ¨ GPU å†…å­˜ä¸Šçš„å‰¯æœ¬ã€‚
        to: è¿”å›žå…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹çš„å…³é”®ç‚¹å¼ é‡å‰¯æœ¬ã€‚

    Examples:
        >>> import torch
        >>> from ultralytics.engine.results import Keypoints
        >>> keypoints_data = torch.rand(1, 17, 3)  # 1 ä¸ªæ£€æµ‹, 17 ä¸ªå…³é”®ç‚¹, (x, y, conf)
        >>> orig_shape = (480, 640)  # åŽŸå§‹å›¾åƒå½¢çŠ¶ (é«˜åº¦, å®½åº¦)
        >>> keypoints = Keypoints(keypoints_data, orig_shape)
        >>> print(keypoints.xy.shape)  # è®¿é—® xy åæ ‡
        >>> print(keypoints.conf)  # è®¿é—®ç½®ä¿¡åº¦å€¼
        >>> keypoints_cpu = keypoints.cpu()  # å°†å…³é”®ç‚¹ç§»è‡³ CPU
    """

    def __init__(self, keypoints: torch.Tensor | np.ndarray, orig_shape: tuple[int, int]) -> None:
        """ä½¿ç”¨æ£€æµ‹å…³é”®ç‚¹å’ŒåŽŸå§‹å›¾åƒå°ºå¯¸åˆå§‹åŒ– Keypoints å¯¹è±¡ã€‚

        è¯¥æ–¹æ³•å¤„ç†è¾“å…¥å…³é”®ç‚¹å¼ é‡,å¤„ç†äºŒç»´å’Œä¸‰ç»´æ ¼å¼ã€‚å¯¹äºŽä¸‰ç»´å¼ é‡ (x, y, confidence),
        å®ƒé€šè¿‡å°†ä½Žç½®ä¿¡åº¦å…³é”®ç‚¹çš„åæ ‡è®¾ç½®ä¸ºé›¶æ¥å±è”½å®ƒä»¬ã€‚

        Args:
            keypoints (torch.Tensor): åŒ…å«å…³é”®ç‚¹æ•°æ®çš„å¼ é‡ã€‚å½¢çŠ¶å¯ä»¥æ˜¯:
                - (num_objects, num_keypoints, 2) ä»…ç”¨äºŽ x, y åæ ‡
                - (num_objects, num_keypoints, 3) ç”¨äºŽ x, y åæ ‡å’Œç½®ä¿¡åº¦åˆ†æ•°
            orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚
        """
        if keypoints.ndim == 2:
            keypoints = keypoints[None, :]
        super().__init__(keypoints, orig_shape)
        self.has_visible = self.data.shape[-1] == 3

    @property
    @lru_cache(maxsize=1)
    def xy(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žå…³é”®ç‚¹çš„ x, y åæ ‡ã€‚

        Returns:
            (torch.Tensor): åŒ…å«å…³é”®ç‚¹ x, y åæ ‡çš„å¼ é‡,å½¢çŠ¶ä¸º (N, K, 2),å…¶ä¸­ N æ˜¯æ£€æµ‹æ•°é‡,
                K æ˜¯æ¯ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹æ•°é‡ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> keypoints = results[0].keypoints
            >>> xy = keypoints.xy
            >>> print(xy.shape)  # (N, K, 2)
            >>> print(xy[0])  # ç¬¬ä¸€ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹ x, y åæ ‡

        Notes:
            - è¿”å›žçš„åæ ‡æ˜¯ç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå°ºå¯¸çš„åƒç´ å•ä½ã€‚
            - å¦‚æžœå…³é”®ç‚¹ä½¿ç”¨ç½®ä¿¡åº¦å€¼åˆå§‹åŒ–,åˆ™ä»…è¿”å›žç½®ä¿¡åº¦ >= 0.5 çš„å…³é”®ç‚¹ã€‚
            - æ­¤å±žæ€§ä½¿ç”¨ LRU ç¼“å­˜ä»¥æé«˜é‡å¤è®¿é—®çš„æ€§èƒ½ã€‚
        """
        return self.data[..., :2]

    @property
    @lru_cache(maxsize=1)
    def xyn(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå¤§å°çš„å…³é”®ç‚¹å½’ä¸€åŒ–åæ ‡ (x, y)ã€‚

        Returns:
            (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (N, K, 2) çš„å¼ é‡æˆ–æ•°ç»„,åŒ…å«å½’ä¸€åŒ–å…³é”®ç‚¹åæ ‡,
                å…¶ä¸­ N æ˜¯å®žä¾‹æ•°é‡,K æ˜¯å…³é”®ç‚¹æ•°é‡,æœ€åŽä¸€ä¸ªç»´åº¦åŒ…å« [0, 1] èŒƒå›´å†…çš„ [x, y] å€¼ã€‚

        Examples:
            >>> keypoints = Keypoints(torch.rand(1, 17, 2), orig_shape=(480, 640))
            >>> normalized_kpts = keypoints.xyn
            >>> print(normalized_kpts.shape)
            torch.Size([1, 17, 2])
        """
        xy = self.xy.clone() if isinstance(self.xy, torch.Tensor) else np.copy(self.xy)
        xy[..., 0] /= self.orig_shape[1]
        xy[..., 1] /= self.orig_shape[0]
        return xy

    @property
    @lru_cache(maxsize=1)
    def conf(self) -> torch.Tensor | np.ndarray | None:
        """è¿”å›žæ¯ä¸ªå…³é”®ç‚¹çš„ç½®ä¿¡åº¦å€¼ã€‚

        Returns:
            (torch.Tensor | None): åŒ…å«æ¯ä¸ªå…³é”®ç‚¹ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡(å¦‚æžœå¯ç”¨),å¦åˆ™ä¸º Noneã€‚
                å¯¹äºŽæ‰¹é‡æ•°æ®,å½¢çŠ¶ä¸º (num_detections, num_keypoints);å¯¹äºŽå•ä¸ªæ£€æµ‹,å½¢çŠ¶ä¸º (num_keypoints,)ã€‚

        Examples:
            >>> keypoints = Keypoints(torch.rand(1, 17, 3), orig_shape=(640, 640))  # 1 ä¸ªæ£€æµ‹, 17 ä¸ªå…³é”®ç‚¹
            >>> conf = keypoints.conf
            >>> print(conf.shape)  # torch.Size([1, 17])
        """
        return self.data[..., 2] if self.has_visible else None


class Probs(BaseTensor):
    """ç”¨äºŽå­˜å‚¨å’Œæ“ä½œåˆ†ç±»æ¦‚çŽ‡çš„ç±»ã€‚

    è¯¥ç±»æ‰©å±• BaseTensor å¹¶æä¾›ç”¨äºŽè®¿é—®å’Œæ“ä½œåˆ†ç±»æ¦‚çŽ‡çš„æ–¹æ³•,åŒ…æ‹¬ top-1 å’Œ top-5 é¢„æµ‹ã€‚

    Attributes:
        data (torch.Tensor | np.ndarray): åŒ…å«åˆ†ç±»æ¦‚çŽ‡çš„åŽŸå§‹å¼ é‡æˆ–æ•°ç»„ã€‚
        orig_shape (tuple | None): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚æ­¤ç±»ä¸­æœªä½¿ç”¨ã€‚
        top1 (int): å…·æœ‰æœ€é«˜æ¦‚çŽ‡çš„ç±»åˆ«ç´¢å¼•ã€‚
        top5 (list[int]): æŒ‰æ¦‚çŽ‡æŽ’åºçš„å‰ 5 ä¸ªç±»åˆ«çš„ç´¢å¼•ã€‚
        top1conf (torch.Tensor | np.ndarray): top 1 ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        top5conf (torch.Tensor | np.ndarray): top 5 ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

    Methods:
        cpu: è¿”å›žæ¦‚çŽ‡å¼ é‡åœ¨ CPU å†…å­˜ä¸Šçš„å‰¯æœ¬ã€‚
        numpy: è¿”å›žæ¦‚çŽ‡å¼ é‡çš„ numpy æ•°ç»„å‰¯æœ¬ã€‚
        cuda: è¿”å›žæ¦‚çŽ‡å¼ é‡åœ¨ GPU å†…å­˜ä¸Šçš„å‰¯æœ¬ã€‚
        to: è¿”å›žå…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹çš„æ¦‚çŽ‡å¼ é‡å‰¯æœ¬ã€‚

    Examples:
        >>> probs = torch.tensor([0.1, 0.3, 0.6])
        >>> p = Probs(probs)
        >>> print(p.top1)
        2
        >>> print(p.top5)
        [2, 1, 0]
        >>> print(p.top1conf)
        tensor(0.6000)
        >>> print(p.top5conf)
        tensor([0.6000, 0.3000, 0.1000])
    """

    def __init__(self, probs: torch.Tensor | np.ndarray, orig_shape: tuple[int, int] | None = None) -> None:
        """ä½¿ç”¨åˆ†ç±»æ¦‚çŽ‡åˆå§‹åŒ– Probs ç±»ã€‚

        è¯¥ç±»å­˜å‚¨å’Œç®¡ç†åˆ†ç±»æ¦‚çŽ‡,æä¾›å¯¹æœ€é«˜é¢„æµ‹åŠå…¶ç½®ä¿¡åº¦çš„è½»æ¾è®¿é—®ã€‚

        Args:
            probs (torch.Tensor | np.ndarray): åˆ†ç±»æ¦‚çŽ‡çš„ä¸€ç»´å¼ é‡æˆ–æ•°ç»„ã€‚
            orig_shape (tuple | None): åŽŸå§‹å›¾åƒå½¢çŠ¶,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
                æ­¤ç±»ä¸­æœªä½¿ç”¨,ä½†ä¸ºä¸Žå…¶ä»–ç»“æžœç±»ä¿æŒä¸€è‡´è€Œä¿ç•™ã€‚
        """
        super().__init__(probs, orig_shape)

    @property
    @lru_cache(maxsize=1)
    def top1(self) -> int:
        """è¿”å›žå…·æœ‰æœ€é«˜æ¦‚çŽ‡çš„ç±»åˆ«ç´¢å¼•ã€‚

        Returns:
            (int): å…·æœ‰æœ€é«˜æ¦‚çŽ‡çš„ç±»åˆ«ç´¢å¼•ã€‚

        Examples:
            >>> probs = Probs(torch.tensor([0.1, 0.3, 0.6]))
            >>> probs.top1
            2
        """
        return int(self.data.argmax())

    @property
    @lru_cache(maxsize=1)
    def top5(self) -> list[int]:
        """è¿”å›žå‰ 5 ä¸ªç±»åˆ«æ¦‚çŽ‡çš„ç´¢å¼•ã€‚

        Returns:
            (list[int]): åŒ…å«å‰ 5 ä¸ªç±»åˆ«æ¦‚çŽ‡ç´¢å¼•çš„åˆ—è¡¨,æŒ‰é™åºæŽ’åˆ—ã€‚

        Examples:
            >>> probs = Probs(torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5]))
            >>> print(probs.top5)
            [4, 3, 2, 1, 0]
        """
        return (-self.data).argsort(0)[:5].tolist()  # è¿™ç§æ–¹å¼é€‚ç”¨äºŽ torch å’Œ numpy

    @property
    @lru_cache(maxsize=1)
    def top1conf(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žæœ€é«˜æ¦‚çŽ‡ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±žæ€§ä»Žåˆ†ç±»ç»“æžœä¸­æ£€ç´¢å…·æœ‰æœ€é«˜é¢„æµ‹æ¦‚çŽ‡çš„ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°(æ¦‚çŽ‡)ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å« top 1 ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡ã€‚

        Examples:
            >>> results = model("image.jpg")  # å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»
            >>> probs = results[0].probs  # èŽ·å–åˆ†ç±»æ¦‚çŽ‡
            >>> top1_confidence = probs.top1conf  # èŽ·å– top 1 ç±»åˆ«çš„ç½®ä¿¡åº¦
            >>> print(f"Top 1 class confidence: {top1_confidence.item():.4f}")
        """
        return self.data[self.top1]

    @property
    @lru_cache(maxsize=1)
    def top5conf(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žå‰ 5 ä¸ªåˆ†ç±»é¢„æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±žæ€§æ£€ç´¢ä¸Žæ¨¡åž‹é¢„æµ‹çš„å‰ 5 ä¸ªç±»åˆ«æ¦‚çŽ‡å¯¹åº”çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        å®ƒæä¾›äº†ä¸€ç§å¿«é€Ÿè®¿é—®æœ€å¯èƒ½çš„ç±»åˆ«é¢„æµ‹åŠå…¶ç›¸å…³ç½®ä¿¡åº¦çº§åˆ«çš„æ–¹æ³•ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å«å‰ 5 ä¸ªé¢„æµ‹ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡æˆ–æ•°ç»„,æŒ‰æ¦‚çŽ‡é™åºæŽ’åˆ—ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> probs = results[0].probs
            >>> top5_conf = probs.top5conf
            >>> print(top5_conf)  # æ‰“å°å‰ 5 ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°
        """
        return self.data[self.top5]


class OBB(BaseTensor):
    """ç”¨äºŽå­˜å‚¨å’Œæ“ä½œæœ‰å‘è¾¹ç•Œæ¡† (OBB) çš„ç±»ã€‚

    è¯¥ç±»æä¾›å¤„ç†æœ‰å‘è¾¹ç•Œæ¡†çš„åŠŸèƒ½,åŒ…æ‹¬ä¸åŒæ ¼å¼ä¹‹é—´çš„è½¬æ¢ã€å½’ä¸€åŒ–ä»¥åŠå¯¹è¾¹ç•Œæ¡†å„ç§å±žæ€§çš„è®¿é—®ã€‚
    å®ƒæ”¯æŒè·Ÿè¸ªå’Œéžè·Ÿè¸ªåœºæ™¯ã€‚

    Attributes:
        data (torch.Tensor): åŒ…å«è¾¹ç•Œæ¡†åæ ‡å’Œå…³è”æ•°æ®çš„åŽŸå§‹ OBB å¼ é‡ã€‚
        orig_shape (tuple): åŽŸå§‹å›¾åƒå¤§å°,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        is_track (bool): æŒ‡ç¤ºè¾¹ç•Œæ¡†æ•°æ®ä¸­æ˜¯å¦åŒ…å«è·Ÿè¸ª IDã€‚
        xywhr (torch.Tensor | np.ndarray): [x_center, y_center, width, height, rotation] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚
        conf (torch.Tensor | np.ndarray): æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        cls (torch.Tensor | np.ndarray): æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç±»åˆ«æ ‡ç­¾ã€‚
        id (torch.Tensor | np.ndarray): æ¯ä¸ªè¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID(å¦‚æžœå¯ç”¨)ã€‚
        xyxyxyxy (torch.Tensor | np.ndarray): 8 ç‚¹ [x1, y1, x2, y2, x3, y3, x4, y4] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚
        xyxyxyxyn (torch.Tensor | np.ndarray): ç›¸å¯¹äºŽ orig_shape å½’ä¸€åŒ–çš„ 8 ç‚¹åæ ‡ã€‚
        xyxy (torch.Tensor | np.ndarray): [x1, y1, x2, y2] æ ¼å¼çš„è½´å¯¹é½è¾¹ç•Œæ¡†ã€‚

    Methods:
        cpu: è¿”å›žæ‰€æœ‰å¼ é‡åœ¨ CPU å†…å­˜ä¸Šçš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        numpy: è¿”å›žæ‰€æœ‰å¼ é‡ä¸º numpy æ•°ç»„çš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        cuda: è¿”å›žæ‰€æœ‰å¼ é‡åœ¨ GPU å†…å­˜ä¸Šçš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        to: è¿”å›žå¼ é‡åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»åž‹ä¸Šçš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚

    Examples:
        >>> boxes = torch.tensor([[100, 50, 150, 100, 30, 0.9, 0]])  # xywhr, conf, cls
        >>> obb = OBB(boxes, orig_shape=(480, 640))
        >>> print(obb.xyxyxyxy)
        >>> print(obb.conf)
        >>> print(obb.cls)
    """

    def __init__(self, boxes: torch.Tensor | np.ndarray, orig_shape: tuple[int, int]) -> None:
        """ä½¿ç”¨æœ‰å‘è¾¹ç•Œæ¡†æ•°æ®å’ŒåŽŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ– OBB(æœ‰å‘è¾¹ç•Œæ¡†)å®žä¾‹ã€‚

        è¯¥ç±»å­˜å‚¨å’Œæ“ä½œç”¨äºŽç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æœ‰å‘è¾¹ç•Œæ¡† (OBB)ã€‚å®ƒæä¾›è®¿é—®å’Œè½¬æ¢ OBB æ•°æ®çš„å„ç§å±žæ€§å’Œæ–¹æ³•ã€‚

        Args:
            boxes (torch.Tensor | np.ndarray): åŒ…å«æ£€æµ‹æ¡†çš„å¼ é‡æˆ– numpy æ•°ç»„,å½¢çŠ¶ä¸º (num_boxes, 7) æˆ– (num_boxes, 8)ã€‚
                æœ€åŽä¸¤åˆ—åŒ…å«ç½®ä¿¡åº¦å’Œç±»åˆ«å€¼ã€‚å¦‚æžœå­˜åœ¨,å€’æ•°ç¬¬ä¸‰åˆ—åŒ…å«è·Ÿè¸ª ID,ç¬¬äº”åˆ—åŒ…å«æ—‹è½¬è§’åº¦ã€‚
            orig_shape (tuple[int, int]): åŽŸå§‹å›¾åƒå¤§å°,æ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚

        Raises:
            AssertionError: å¦‚æžœæ¯ä¸ªè¾¹ç•Œæ¡†çš„å€¼æ•°é‡ä¸æ˜¯ 7 æˆ– 8ã€‚
        """
        if boxes.ndim == 1:
            boxes = boxes[None, :]
        n = boxes.shape[-1]
        assert n in {7, 8}, f"expected 7 or 8 values but got {n}"  # xywh, rotation, track_id, conf, cls
        super().__init__(boxes, orig_shape)
        self.is_track = n == 8
        self.orig_shape = orig_shape

    @property
    def xywhr(self) -> torch.Tensor | np.ndarray:
        """è¿”å›ž [x_center, y_center, width, height, rotation] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å«æœ‰å‘è¾¹ç•Œæ¡†çš„å¼ é‡æˆ– numpy æ•°ç»„,
                æ ¼å¼ä¸º [x_center, y_center, width, height, rotation]ã€‚å½¢çŠ¶ä¸º (N, 5),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> obb = results[0].obb
            >>> xywhr = obb.xywhr
            >>> print(xywhr.shape)
            torch.Size([3, 5])
        """
        return self.data[:, :5]

    @property
    def conf(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žæœ‰å‘è¾¹ç•Œæ¡† (OBB) çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±žæ€§æ£€ç´¢ä¸Žæ¯ä¸ª OBB æ£€æµ‹ç›¸å…³çš„ç½®ä¿¡åº¦å€¼ã€‚ç½®ä¿¡åº¦åˆ†æ•°è¡¨ç¤ºæ¨¡åž‹å¯¹æ£€æµ‹çš„ç¡®å®šæ€§ã€‚

        Returns:
            (torch.Tensor | np.ndarray): å½¢çŠ¶ä¸º (N,) çš„å¼ é‡æˆ– numpy æ•°ç»„,åŒ…å« N ä¸ªæ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°,
                æ¯ä¸ªåˆ†æ•°åœ¨ [0, 1] èŒƒå›´å†…ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> obb_result = results[0].obb
            >>> confidence_scores = obb_result.conf
            >>> print(confidence_scores)
        """
        return self.data[:, -2]

    @property
    def cls(self) -> torch.Tensor | np.ndarray:
        """è¿”å›žæœ‰å‘è¾¹ç•Œæ¡†çš„ç±»åˆ«å€¼ã€‚

        Returns:
            (torch.Tensor | np.ndarray): åŒ…å«æ¯ä¸ªæœ‰å‘è¾¹ç•Œæ¡†çš„ç±»åˆ«å€¼çš„å¼ é‡æˆ– numpy æ•°ç»„ã€‚
                å½¢çŠ¶ä¸º (N,),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚

        Examples:
            >>> results = model("image.jpg")
            >>> result = results[0]
            >>> obb = result.obb
            >>> class_values = obb.cls
            >>> print(class_values)
        """
        return self.data[:, -1]

    @property
    def id(self) -> torch.Tensor | np.ndarray | None:
        """è¿”å›žæœ‰å‘è¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID(å¦‚æžœå¯ç”¨)ã€‚

        Returns:
            (torch.Tensor | np.ndarray | None): åŒ…å«æ¯ä¸ªæœ‰å‘è¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID çš„å¼ é‡æˆ– numpy æ•°ç»„ã€‚
                å¦‚æžœè·Ÿè¸ª ID ä¸å¯ç”¨,åˆ™è¿”å›ž Noneã€‚

        Examples:
            >>> results = model("image.jpg", tracker=True)  # ä½¿ç”¨è·Ÿè¸ªè¿è¡ŒæŽ¨ç†
            >>> for result in results:
            ...     if result.obb is not None:
            ...         track_ids = result.obb.id
            ...         if track_ids is not None:
            ...             print(f"Tracking IDs: {track_ids}")
        """
        return self.data[:, -3] if self.is_track else None

    @property
    @lru_cache(maxsize=2)
    def xyxyxyxy(self) -> torch.Tensor | np.ndarray:
        """å°† OBB æ ¼å¼è½¬æ¢ä¸ºæ—‹è½¬è¾¹ç•Œæ¡†çš„ 8 ç‚¹ (xyxyxyxy) åæ ‡æ ¼å¼ã€‚

        Returns:
            (torch.Tensor | np.ndarray): xyxyxyxy æ ¼å¼çš„æ—‹è½¬è¾¹ç•Œæ¡†,å½¢çŠ¶ä¸º (N, 4, 2),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚
                æ¯ä¸ªè¾¹ç•Œæ¡†ç”± 4 ä¸ªç‚¹ (x, y) è¡¨ç¤º,ä»Žå·¦ä¸Šè§’å¼€å§‹é¡ºæ—¶é’ˆç§»åŠ¨ã€‚

        Examples:
            >>> obb = OBB(torch.tensor([[100, 100, 50, 30, 0.5, 0.9, 0]]), orig_shape=(640, 640))
            >>> xyxyxyxy = obb.xyxyxyxy
            >>> print(xyxyxyxy.shape)
            torch.Size([1, 4, 2])
        """
        return ops.xywhr2xyxyxyxy(self.xywhr)

    @property
    @lru_cache(maxsize=2)
    def xyxyxyxyn(self) -> torch.Tensor | np.ndarray:
        """å°†æ—‹è½¬è¾¹ç•Œæ¡†è½¬æ¢ä¸ºå½’ä¸€åŒ–çš„ xyxyxyxy æ ¼å¼ã€‚

        Returns:
            (torch.Tensor | np.ndarray): xyxyxyxy æ ¼å¼çš„å½’ä¸€åŒ–æ—‹è½¬è¾¹ç•Œæ¡†,å½¢çŠ¶ä¸º (N, 4, 2),
                å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†ç”± 4 ä¸ªç‚¹ (x, y) è¡¨ç¤º,ç›¸å¯¹äºŽåŽŸå§‹å›¾åƒå°ºå¯¸è¿›è¡Œå½’ä¸€åŒ–ã€‚

        Examples:
            >>> obb = OBB(torch.rand(10, 7), orig_shape=(640, 480))  # 10 ä¸ªéšæœº OBB
            >>> normalized_boxes = obb.xyxyxyxyn
            >>> print(normalized_boxes.shape)
            torch.Size([10, 4, 2])
        """
        xyxyxyxyn = self.xyxyxyxy.clone() if isinstance(self.xyxyxyxy, torch.Tensor) else np.copy(self.xyxyxyxy)
        xyxyxyxyn[..., 0] /= self.orig_shape[1]
        xyxyxyxyn[..., 1] /= self.orig_shape[0]
        return xyxyxyxyn

    @property
    @lru_cache(maxsize=2)
    def xyxy(self) -> torch.Tensor | np.ndarray:
        """å°†æœ‰å‘è¾¹ç•Œæ¡† (OBB) è½¬æ¢ä¸º xyxy æ ¼å¼çš„è½´å¯¹é½è¾¹ç•Œæ¡†ã€‚

        è¯¥å±žæ€§è®¡ç®—æ¯ä¸ªæœ‰å‘è¾¹ç•Œæ¡†çš„æœ€å°å¤–æŽ¥çŸ©å½¢,å¹¶ä»¥ xyxy æ ¼å¼ (x1, y1, x2, y2) è¿”å›žã€‚
        è¿™å¯¹äºŽéœ€è¦è½´å¯¹é½è¾¹ç•Œæ¡†çš„æ“ä½œå¾ˆæœ‰ç”¨,ä¾‹å¦‚ä¸Žéžæ—‹è½¬è¾¹ç•Œæ¡†çš„ IoU è®¡ç®—ã€‚

        Returns:
            (torch.Tensor | np.ndarray): xyxy æ ¼å¼çš„è½´å¯¹é½è¾¹ç•Œæ¡†,å½¢çŠ¶ä¸º (N, 4),å…¶ä¸­ N æ˜¯è¾¹ç•Œæ¡†æ•°é‡ã€‚
                æ¯è¡ŒåŒ…å« [x1, y1, x2, y2] åæ ‡ã€‚

        Examples:
            >>> import torch
            >>> from ultralytics import YOLO
            >>> model = YOLO("yolo11n-obb.pt")
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     obb = result.obb
            ...     if obb is not None:
            ...         xyxy_boxes = obb.xyxy
            ...         print(xyxy_boxes.shape)  # (N, 4)

        Notes:
            - è¯¥æ–¹æ³•é€šè¿‡æœ€å°å¤–æŽ¥çŸ©å½¢è¿‘ä¼¼ OBBã€‚
            - è¿”å›žçš„æ ¼å¼ä¸Žæ ‡å‡†ç›®æ ‡æ£€æµ‹æŒ‡æ ‡å’Œå¯è§†åŒ–å·¥å…·å…¼å®¹ã€‚
            - è¯¥å±žæ€§ä½¿ç”¨ç¼“å­˜ä»¥æé«˜é‡å¤è®¿é—®çš„æ€§èƒ½ã€‚
        """
        x = self.xyxyxyxy[..., 0]
        y = self.xyxyxyxy[..., 1]
        return (
            torch.stack([x.amin(1), y.amin(1), x.amax(1), y.amax(1)], -1)
            if isinstance(x, torch.Tensor)
            else np.stack([x.min(1), y.min(1), x.max(1), y.max(1)], -1)
        )
