# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
SAM model interface.

This module provides an interface to the Segment Anything Model (SAM) from Ultralytics, designed for real-time image
segmentation tasks. The SAM model allows for promptable segmentation with unparalleled versatility in image analysis,
and has been trained on the SA-1B dataset. It features zero-shot performance capabilities, enabling it to adapt to new
image distributions and tasks without prior knowledge.

Key Features:
    - Promptable segmentation
    - Real-time performance
    - Zero-shot transfer capabilities
    - Trained on SA-1B dataset

---

SAM æ¨¡åž‹æŽ¥å£æ¨¡å—

è¯¥æ¨¡å—æä¾›äº† Segment Anything Model (SAM) çš„ Ultralytics å®žçŽ°æŽ¥å£ã€‚
SAM æ˜¯ Meta AI å¼€å‘çš„é€šç”¨å›¾åƒåˆ†å‰²æ¨¡åž‹ï¼Œèƒ½å¤Ÿæ ¹æ®å„ç§æç¤ºï¼ˆç‚¹ã€æ¡†ã€æŽ©ç ï¼‰è¿›è¡Œå®žæ—¶åˆ†å‰²ã€‚

æ ¸å¿ƒç‰¹æ€§:
    - æç¤ºå¼åˆ†å‰²: æ”¯æŒç‚¹ã€è¾¹ç•Œæ¡†ã€æŽ©ç ç­‰å¤šç§æç¤ºæ–¹å¼
    - å®žæ—¶æ€§èƒ½: ä¼˜åŒ–çš„æŽ¨ç†é€Ÿåº¦ï¼Œé€‚åˆå®žæ—¶åº”ç”¨
    - é›¶æ ·æœ¬è¿ç§»: æ— éœ€é¢å¤–è®­ç»ƒå³å¯é€‚åº”æ–°çš„å›¾åƒåˆ†å¸ƒå’Œä»»åŠ¡
    - SA-1B æ•°æ®é›†: åœ¨åŒ…å« 1100 ä¸‡å¼ å›¾åƒçš„ SA-1B æ•°æ®é›†ä¸Šè®­ç»ƒ

æŠ€æœ¯ç‰¹ç‚¹:
    - åŸºäºŽ Vision Transformer (ViT) çš„å›¾åƒç¼–ç å™¨
    - è½»é‡çº§çš„æŽ©ç è§£ç å™¨
    - çµæ´»çš„æç¤ºç¼–ç å™¨ï¼Œæ”¯æŒå¤šç§æç¤ºç±»åž‹
    - æ”¯æŒ SAMã€SAM2 å’Œ SAM3 å¤šä¸ªç‰ˆæœ¬
"""

from __future__ import annotations  # å¯ç”¨å»¶è¿Ÿç±»åž‹æ³¨è§£è¯„ä¼°

from pathlib import Path  # ç”¨äºŽè·¯å¾„æ“ä½œ

# å¯¼å…¥åŸºç¡€æ¨¡åž‹ç±»å’Œå·¥å…·å‡½æ•°
from ultralytics.engine.model import Model  # Ultralytics æ¨¡åž‹åŸºç±»
from ultralytics.utils.torch_utils import model_info  # æ¨¡åž‹ä¿¡æ¯æ‰“å°å·¥å…·

# å¯¼å…¥ SAM å„ç‰ˆæœ¬çš„é¢„æµ‹å™¨
from .predict import Predictor, SAM2Predictor, SAM3Predictor


class SAM(Model):
    """SAM (Segment Anything Model) interface class for real-time image segmentation tasks.

    This class provides an interface to the Segment Anything Model (SAM) from Ultralytics, designed for promptable
    segmentation with versatility in image analysis. It supports various prompts such as bounding boxes, points, or
    labels, and features zero-shot performance capabilities.

    Attributes:
        model (torch.nn.Module): The loaded SAM model.
        is_sam2 (bool): Indicates whether the model is SAM2 variant.
        task (str): The task type, set to "segment" for SAM models.

    Methods:
        predict: Perform segmentation prediction on the given image or video source.
        info: Log information about the SAM model.

    Examples:
        >>> sam = SAM("sam_b.pt")
        >>> results = sam.predict("image.jpg", points=[[500, 375]])
        >>> for r in results:
        ...     print(f"Detected {len(r.masks)} masks")

    ---

    SAM (Segment Anything Model) æŽ¥å£ç±»ï¼Œç”¨äºŽå®žæ—¶å›¾åƒåˆ†å‰²ä»»åŠ¡

    è¯¥ç±»æä¾›äº† SAM æ¨¡åž‹çš„ç»Ÿä¸€æŽ¥å£ï¼Œæ”¯æŒæç¤ºå¼åˆ†å‰²ã€‚å¯ä»¥ä½¿ç”¨ç‚¹ã€è¾¹ç•Œæ¡†æˆ–æ ‡ç­¾ä½œä¸ºæç¤ºï¼Œ
    æ¨¡åž‹ä¼šç”Ÿæˆå¯¹åº”çš„åˆ†å‰²æŽ©ç ã€‚å…·æœ‰é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œæ— éœ€å¾®è°ƒå³å¯åº”ç”¨äºŽæ–°åœºæ™¯ã€‚

    å±žæ€§:
        model (torch.nn.Module): åŠ è½½çš„ SAM æ¨¡åž‹å®žä¾‹
        is_sam2 (bool): æ ‡è¯†æ˜¯å¦ä¸º SAM2 ç‰ˆæœ¬
        is_sam3 (bool): æ ‡è¯†æ˜¯å¦ä¸º SAM3 ç‰ˆæœ¬
        task (str): ä»»åŠ¡ç±»åž‹ï¼Œå¯¹äºŽ SAM æ¨¡åž‹å›ºå®šä¸º "segment"

    æ–¹æ³•:
        predict: å¯¹ç»™å®šçš„å›¾åƒæˆ–è§†é¢‘æºæ‰§è¡Œåˆ†å‰²é¢„æµ‹
        info: è¾“å‡º SAM æ¨¡åž‹çš„è¯¦ç»†ä¿¡æ¯
        __call__: predict æ–¹æ³•çš„åˆ«åï¼Œæä¾›æ›´ä¾¿æ·çš„è°ƒç”¨æ–¹å¼

    ç¤ºä¾‹:
        >>> sam = SAM("sam_b.pt")  # åŠ è½½ SAM Base æ¨¡åž‹
        >>> results = sam.predict("image.jpg", points=[[500, 375]])  # ä½¿ç”¨ç‚¹æç¤ºè¿›è¡Œåˆ†å‰²
        >>> for r in results:
        ...     print(f"æ£€æµ‹åˆ° {len(r.masks)} ä¸ªæŽ©ç ")
    """

    def __init__(self, model: str = "sam_b.pt") -> None:
        """Initialize the SAM (Segment Anything Model) instance.

        Args:
            model (str): Path to the pre-trained SAM model file. File should have a .pt or .pth extension.

        Raises:
            NotImplementedError: If the model file extension is not .pt or .pth.

        ---

        åˆå§‹åŒ– SAM (Segment Anything Model) å®žä¾‹

        Args:
            model (str): é¢„è®­ç»ƒ SAM æ¨¡åž‹æ–‡ä»¶çš„è·¯å¾„ï¼Œæ–‡ä»¶æ‰©å±•ååº”ä¸º .pt æˆ– .pth
                é»˜è®¤: "sam_b.pt" (SAM Base æ¨¡åž‹)
                å¯é€‰: "sam_l.pt" (Large), "sam_h.pt" (Huge), "mobile_sam.pt" (ç§»åŠ¨ç«¯)

        Raises:
            NotImplementedError: å¦‚æžœæ¨¡åž‹æ–‡ä»¶æ‰©å±•åä¸æ˜¯ .pt æˆ– .pth
        """
        # éªŒè¯æ¨¡åž‹æ–‡ä»¶æ ¼å¼
        if model and Path(model).suffix not in {".pt", ".pth"}:
            raise NotImplementedError("SAM prediction requires pre-trained *.pt or *.pth model.")
        # æ£€æµ‹æ¨¡åž‹ç‰ˆæœ¬ï¼ˆé€šè¿‡æ–‡ä»¶ååˆ¤æ–­ï¼‰
        self.is_sam2 = "sam2" in Path(model).stem  # æ˜¯å¦ä¸º SAM2 ç‰ˆæœ¬
        self.is_sam3 = "sam3" in Path(model).stem  # æ˜¯å¦ä¸º SAM3 ç‰ˆæœ¬
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œè®¾ç½®ä»»åŠ¡ç±»åž‹ä¸ºåˆ†å‰²
        super().__init__(model=model, task="segment")

    def _load(self, weights: str, task=None):
        """Load the specified weights into the SAM model.

        Args:
            weights (str): Path to the weights file. Should be a .pt or .pth file containing the model parameters.
            task (str | None): Task name. If provided, it specifies the particular task the model is being loaded for.

        Examples:
            >>> sam = SAM("sam_b.pt")
            >>> sam._load("path/to/custom_weights.pt")

        ---

        åŠ è½½æŒ‡å®šçš„æƒé‡æ–‡ä»¶åˆ° SAM æ¨¡åž‹

        æ ¹æ®æ¨¡åž‹ç‰ˆæœ¬ï¼ˆSAM3 æˆ– SAM/SAM2ï¼‰é€‰æ‹©ç›¸åº”çš„æž„å»ºå‡½æ•°åŠ è½½æ¨¡åž‹æƒé‡ã€‚
        SAM3 ä½¿ç”¨ build_interactive_sam3ï¼Œå…¶ä»–ç‰ˆæœ¬ä½¿ç”¨ build_samã€‚

        Args:
            weights (str): æƒé‡æ–‡ä»¶è·¯å¾„ï¼Œåº”ä¸ºåŒ…å«æ¨¡åž‹å‚æ•°çš„ .pt æˆ– .pth æ–‡ä»¶
            task (str | None): ä»»åŠ¡åç§°ï¼ˆå¯é€‰ï¼‰ï¼ŒæŒ‡å®šæ¨¡åž‹åŠ è½½çš„ç‰¹å®šä»»åŠ¡

        ç¤ºä¾‹:
            >>> sam = SAM("sam_b.pt")
            >>> sam._load("path/to/custom_weights.pt")  # åŠ è½½è‡ªå®šä¹‰æƒé‡
        """
        if self.is_sam3:
            # SAM3 ç‰ˆæœ¬ï¼šä½¿ç”¨ä¸“ç”¨çš„äº¤äº’å¼æž„å»ºå‡½æ•°
            from .build_sam3 import build_interactive_sam3

            self.model = build_interactive_sam3(weights)
        else:
            # SAM/SAM2 ç‰ˆæœ¬ï¼šä½¿ç”¨æ ‡å‡†æž„å»ºå‡½æ•°ï¼ˆé¦–æ¬¡å¯¼å…¥è¾ƒæ…¢ï¼‰
            from .build import build_sam  # slow import

            self.model = build_sam(weights)

    def predict(self, source, stream: bool = False, bboxes=None, points=None, labels=None, **kwargs):
        """Perform segmentation prediction on the given image or video source.

        Args:
            source (str | PIL.Image | np.ndarray): Path to the image or video file, or a PIL.Image object, or a
                np.ndarray object.
            stream (bool): If True, enables real-time streaming.
            bboxes (list[list[float]] | None): List of bounding box coordinates for prompted segmentation.
            points (list[list[float]] | None): List of points for prompted segmentation.
            labels (list[int] | None): List of labels for prompted segmentation.
            **kwargs (Any): Additional keyword arguments for prediction.

        Returns:
            (list): The model predictions.

        Examples:
            >>> sam = SAM("sam_b.pt")
            >>> results = sam.predict("image.jpg", points=[[500, 375]])
            >>> for r in results:
            ...     print(f"Detected {len(r.masks)} masks")

        ---

        å¯¹ç»™å®šçš„å›¾åƒæˆ–è§†é¢‘æºæ‰§è¡Œåˆ†å‰²é¢„æµ‹

        è¯¥æ–¹æ³•æ”¯æŒå¤šç§æç¤ºæ–¹å¼è¿›è¡Œåˆ†å‰²ï¼šç‚¹æç¤ºã€è¾¹ç•Œæ¡†æç¤ºæˆ–æ ‡ç­¾æç¤ºã€‚
        æ¨¡åž‹ä¼šæ ¹æ®æç¤ºç”Ÿæˆå¯¹åº”çš„åˆ†å‰²æŽ©ç ã€‚

        Args:
            source (str | PIL.Image | np.ndarray): å›¾åƒæˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œæˆ– PIL.Image å¯¹è±¡ï¼Œæˆ– numpy æ•°ç»„
            stream (bool): æ˜¯å¦å¯ç”¨å®žæ—¶æµå¼å¤„ç†ï¼Œé»˜è®¤ False
            bboxes (list[list[float]] | None): è¾¹ç•Œæ¡†åæ ‡åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [[x1,y1,x2,y2], ...]
            points (list[list[float]] | None): ç‚¹åæ ‡åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [[x,y], ...]
            labels (list[int] | None): æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨äºŽæŒ‡å®šç‚¹çš„ç±»åž‹ï¼ˆå‰æ™¯/èƒŒæ™¯ï¼‰
            **kwargs (Any): å…¶ä»–é¢„æµ‹å‚æ•°ï¼ˆå¦‚ device, save, show ç­‰ï¼‰

        Returns:
            (list): æ¨¡åž‹é¢„æµ‹ç»“æžœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æžœåŒ…å«åˆ†å‰²æŽ©ç ã€ç½®ä¿¡åº¦ç­‰ä¿¡æ¯

        ç¤ºä¾‹:
            >>> sam = SAM("sam_b.pt")
            >>> # ä½¿ç”¨ç‚¹æç¤º
            >>> results = sam.predict("image.jpg", points=[[500, 375]])
            >>> # ä½¿ç”¨è¾¹ç•Œæ¡†æç¤º
            >>> results = sam.predict("image.jpg", bboxes=[[100, 100, 500, 500]])
            >>> for r in results:
            ...     print(f"æ£€æµ‹åˆ° {len(r.masks)} ä¸ªæŽ©ç ")
        """
        # è®¾ç½®é»˜è®¤å‚æ•°
        overrides = dict(conf=0.25, task="segment", mode="predict", imgsz=1024)
        # åˆå¹¶ç”¨æˆ·å‚æ•°ï¼ˆç”¨æˆ·å‚æ•°ä¼˜å…ˆï¼‰
        kwargs = {**overrides, **kwargs}
        # ç»„ç»‡æç¤ºä¿¡æ¯
        prompts = dict(bboxes=bboxes, points=points, labels=labels)
        # è°ƒç”¨çˆ¶ç±»çš„ predict æ–¹æ³•
        return super().predict(source, stream, prompts=prompts, **kwargs)

    def __call__(self, source=None, stream: bool = False, bboxes=None, points=None, labels=None, **kwargs):
        """Perform segmentation prediction on the given image or video source.

        This method is an alias for the 'predict' method, providing a convenient way to call the SAM model for
        segmentation tasks.

        Args:
            source (str | PIL.Image | np.ndarray | None): Path to the image or video file, or a PIL.Image object, or a
                np.ndarray object.
            stream (bool): If True, enables real-time streaming.
            bboxes (list[list[float]] | None): List of bounding box coordinates for prompted segmentation.
            points (list[list[float]] | None): List of points for prompted segmentation.
            labels (list[int] | None): List of labels for prompted segmentation.
            **kwargs (Any): Additional keyword arguments to be passed to the predict method.

        Returns:
            (list): The model predictions, typically containing segmentation masks and other relevant information.

        Examples:
            >>> sam = SAM("sam_b.pt")
            >>> results = sam("image.jpg", points=[[500, 375]])
            >>> print(f"Detected {len(results[0].masks)} masks")

        ---

        æ‰§è¡Œå›¾åƒæˆ–è§†é¢‘æºçš„åˆ†å‰²é¢„æµ‹ï¼ˆpredict æ–¹æ³•çš„ä¾¿æ·åˆ«åï¼‰

        è¯¥æ–¹æ³•æ˜¯ predict æ–¹æ³•çš„åˆ«åï¼Œå…è®¸ç›´æŽ¥è°ƒç”¨æ¨¡åž‹å®žä¾‹æ¥æ‰§è¡Œåˆ†å‰²ã€‚
        è¿™ç§è°ƒç”¨æ–¹å¼æ›´åŠ ç®€æ´ç›´è§‚ã€‚

        Args:
            source (str | PIL.Image | np.ndarray | None): å›¾åƒæˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œæˆ–å›¾åƒå¯¹è±¡
            stream (bool): æ˜¯å¦å¯ç”¨å®žæ—¶æµå¼å¤„ç†
            bboxes (list[list[float]] | None): è¾¹ç•Œæ¡†åæ ‡åˆ—è¡¨
            points (list[list[float]] | None): ç‚¹åæ ‡åˆ—è¡¨
            labels (list[int] | None): æ ‡ç­¾åˆ—è¡¨
            **kwargs (Any): ä¼ é€’ç»™ predict æ–¹æ³•çš„å…¶ä»–å…³é”®å­—å‚æ•°

        Returns:
            (list): æ¨¡åž‹é¢„æµ‹ç»“æžœï¼ŒåŒ…å«åˆ†å‰²æŽ©ç å’Œç›¸å…³ä¿¡æ¯

        ç¤ºä¾‹:
            >>> sam = SAM("sam_b.pt")
            >>> results = sam("image.jpg", points=[[500, 375]])  # ç›´æŽ¥è°ƒç”¨
            >>> print(f"æ£€æµ‹åˆ° {len(results[0].masks)} ä¸ªæŽ©ç ")
        """
        # å§”æ‰˜ç»™ predict æ–¹æ³•
        return self.predict(source, stream, bboxes, points, labels, **kwargs)

    def info(self, detailed: bool = False, verbose: bool = True):
        """Log information about the SAM model.

        Args:
            detailed (bool): If True, displays detailed information about the model layers and operations.
            verbose (bool): If True, prints the information to the console.

        Returns:
            (tuple): A tuple containing the model's information (string representations of the model).

        Examples:
            >>> sam = SAM("sam_b.pt")
            >>> info = sam.info()
            >>> print(info[0])  # Print summary information

        ---

        è¾“å‡º SAM æ¨¡åž‹çš„è¯¦ç»†ä¿¡æ¯

        Args:
            detailed (bool): æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†çš„å±‚çº§å’Œæ“ä½œä¿¡æ¯ï¼Œé»˜è®¤ False
            verbose (bool): æ˜¯å¦å°†ä¿¡æ¯æ‰“å°åˆ°æŽ§åˆ¶å°ï¼Œé»˜è®¤ True

        Returns:
            (tuple): åŒ…å«æ¨¡åž‹ä¿¡æ¯çš„å…ƒç»„ï¼ˆæ¨¡åž‹çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼‰

        ç¤ºä¾‹:
            >>> sam = SAM("sam_b.pt")
            >>> info = sam.info()  # è¾“å‡ºæ¨¡åž‹æ‘˜è¦ä¿¡æ¯
            >>> info = sam.info(detailed=True)  # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        return model_info(self.model, detailed=detailed, verbose=verbose)

    @property
    def task_map(self) -> dict[str, dict[str, type[Predictor]]]:
        """Provide a mapping from the 'segment' task to its corresponding 'Predictor'.

        Returns:
            (dict[str, dict[str, Type[Predictor]]]): A dictionary mapping the 'segment' task to its corresponding
                Predictor class. For SAM2 models, it maps to SAM2Predictor, otherwise to the standard Predictor.

        Examples:
            >>> sam = SAM("sam_b.pt")
            >>> task_map = sam.task_map
            >>> print(task_map)
            {'segment': {'predictor': <class 'ultralytics.models.sam.predict.Predictor'>}}

        ---

        æä¾›ä»Ž 'segment' ä»»åŠ¡åˆ°å¯¹åº”é¢„æµ‹å™¨çš„æ˜ å°„å…³ç³»

        æ ¹æ® SAM æ¨¡åž‹çš„ç‰ˆæœ¬ï¼ˆSAMã€SAM2 æˆ– SAM3ï¼‰è¿”å›žç›¸åº”çš„é¢„æµ‹å™¨ç±»ã€‚
        è¿™ä¸ªæ˜ å°„ç”¨äºŽè‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„é¢„æµ‹å™¨æ¥å¤„ç†åˆ†å‰²ä»»åŠ¡ã€‚

        Returns:
            (dict[str, dict[str, Type[Predictor]]]): ä»»åŠ¡åˆ°é¢„æµ‹å™¨çš„æ˜ å°„å­—å…¸
                - SAM3: ä½¿ç”¨ SAM3Predictor
                - SAM2: ä½¿ç”¨ SAM2Predictor
                - SAM: ä½¿ç”¨åŸºç¡€ Predictor

        ç¤ºä¾‹:
            >>> sam = SAM("sam_b.pt")
            >>> task_map = sam.task_map
            >>> print(task_map)  # {'segment': {'predictor': <class 'Predictor'>}}
        """
        return {
            "segment": {"predictor": SAM2Predictor if self.is_sam2 else SAM3Predictor if self.is_sam3 else Predictor}
        }
